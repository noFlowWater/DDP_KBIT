{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DDP_KBIT Jupyter Notebook Interface\n",
    "\n",
    "This notebook provides a simple interface to run the DDP_KBIT distributed deep learning system without using command line arguments. It wraps the existing `main.py` functionality for easy experimentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ÏÑ∏ÏÖò Ï¥àÍ∏∞Ìôî (Îß§Î≤à Ïã§Ìñâ ÌïÑÏöî)\n",
    "\n",
    "ÏïÑÎûò ÏÖÄÏùÑ Îß§ ÏÑ∏ÏÖòÎßàÎã§ Í∞ÄÏû• Î®ºÏ†Ä Ïã§ÌñâÌïòÏó¨ Î°úÏª¨ Î™®ÎìàÏóê Ïó∞Í≤∞ÌïòÏÑ∏Ïöî."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.9/site-packages/ignite/handlers/checkpoint.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: config.json not found. Using default values.\n",
      "‚úì Successfully imported DDP_KBIT modules\n",
      "üéâ DDP_KBIT notebook interface ready!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    import ddp_kbit\n",
    "    from ddp_kbit.main import (\n",
    "        setup_logging, \n",
    "        load_external_config,\n",
    "        run_training_mode,\n",
    "        run_experiment_mode, \n",
    "        create_sample_config\n",
    "    )\n",
    "    print(\"‚úì Successfully imported DDP_KBIT modules\")\n",
    "    print(\"üéâ DDP_KBIT notebook interface ready!\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Error importing DDP_KBIT modules: {e}\")\n",
    "    print(\"‚ö†Ô∏è  DDP_KBIT setup incomplete. Some features may not work.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Configuration setup complete\n",
      "Config path: sample_config.json\n",
      "Distributed: False\n",
      "Iterations: 3\n"
     ]
    }
   ],
   "source": [
    "# Setup logging\n",
    "setup_logging(\"INFO\")\n",
    "\n",
    "# Create a mock args object to simulate command line arguments\n",
    "class NotebookArgs:\n",
    "    def __init__(self):\n",
    "        self.config_path = \"sample_config.json\"\n",
    "        self.distributed = False\n",
    "        self.experiment_type = \"single\"\n",
    "        self.iterations = 3\n",
    "        self.log_level = \"INFO\"\n",
    "\n",
    "# Initialize default arguments\n",
    "args = NotebookArgs()\n",
    "\n",
    "print(\"‚úì Configuration setup complete\")\n",
    "print(f\"Config path: {args.config_path}\")\n",
    "print(f\"Distributed: {args.distributed}\")\n",
    "print(f\"Iterations: {args.iterations}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Sample Configuration (Run this first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: config.json not found. Using default values.\n",
      "Created sample_config.json - customize this file for your needs.\n",
      "‚úì Sample configuration created!\n",
      "\n",
      "Current configuration:\n",
      "{\n",
      "  \"training_config\": {\n",
      "    \"base_model_type\": \"NeuralNetwork\",\n",
      "    \"optimizer_class\": \"torch.optim.adam.Adam\",\n",
      "    \"optimizer_params\": {\n",
      "      \"lr\": 0.001\n",
      "    },\n",
      "    \"loss_fn\": \"torch.nn.modules.loss.CrossEntropyLoss\",\n",
      "    \"perform_validation\": true,\n",
      "    \"num_epochs\": 1,\n",
      "    \"batch_size\": 32,\n",
      "    \"metrics\": {\n",
      "      \"loss\": \"Loss\",\n",
      "      \"accuracy\": \"Accuracy\"\n",
      "    }\n",
      "  },\n",
      "  \"mongo_config\": {\n",
      "    \"connection_id\": \"my-mongo-1\",\n",
      "    \"mongo_database\": \"kbit-db\",\n",
      "    \"collection\": \"mnist_train_avro\"\n",
      "  },\n",
      "  \"kafka_config\": {\n",
      "    \"bootstrap_servers\": [\n",
      "      \"155.230.35.200:32100\",\n",
      "      \"155.230.35.213:32100\",\n",
      "      \"155.230.35.215:32100\"\n",
      "    ],\n",
      "    \"data_load_topic\": \"kbit-p3r1\"\n",
      "  },\n",
      "  \"data_loader_config\": {\n",
      "    \"data_loader_type\": \"kafka\",\n",
      "    \"local_data_path\": \"/root/processed_mnist\",\n",
      "    \"offsets_data\": [\n",
      "      \"0:0:19999\",\n",
      "      \"1:0:19999\",\n",
      "      \"2:0:19999\"\n",
      "    ],\n",
      "    \"offsets_data_topic\": \"my-topic-3\",\n",
      "    \"api_config\": {\n",
      "      \"base_url\": \"http://155.230.36.25:3001\",\n",
      "      \"endpoint\": \"data/export\",\n",
      "      \"params\": {\n",
      "        \"connection_id\": \"my-mongo-1\",\n",
      "        \"mongo_database\": \"kbit-db\",\n",
      "        \"collection\": \"mnist_train_avro\",\n",
      "        \"kafka_brokers\": \"155.230.35.200:32100,155.230.35.213:32100,155.230.35.215:32100\",\n",
      "        \"send_topic\": \"kbit-p3r1\"\n",
      "      }\n",
      "    },\n",
      "    \"dataset_split_config\": [\n",
      "      {\n",
      "        \"rate\": 0.85715\n",
      "      },\n",
      "      {\n",
      "        \"rate\": 0.071425\n",
      "      },\n",
      "      {\n",
      "        \"rate\": 0.071425\n",
      "      }\n",
      "    ],\n",
      "    \"consumer_params\": {\n",
      "      \"bootstrap_servers\": [\n",
      "        \"155.230.35.200:32100\",\n",
      "        \"155.230.35.213:32100\",\n",
      "        \"155.230.35.215:32100\"\n",
      "      ]\n",
      "    },\n",
      "    \"payload_config\": {\n",
      "      \"message_format\": \"none\",\n",
      "      \"data_field\": \"data\",\n",
      "      \"label_field\": \"label\",\n",
      "      \"transform_data_fn\": \"transform_mongodb_image\",\n",
      "      \"transform_label_fn\": null\n",
      "    }\n",
      "  },\n",
      "  \"payload_config\": {\n",
      "    \"message_format\": \"none\",\n",
      "    \"data_field\": \"data\",\n",
      "    \"label_field\": \"label\",\n",
      "    \"transform_data_fn\": \"transform_mongodb_image\",\n",
      "    \"transform_label_fn\": null\n",
      "  },\n",
      "  \"metadata\": {\n",
      "    \"generated_from\": \"ddp_kbit.config modules\",\n",
      "    \"description\": \"Sample configuration dynamically generated from existing config modules\",\n",
      "    \"usage_note\": \"This config uses the same settings as defined in the original notebook cell 24\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Create a sample configuration file\n",
    "\n",
    "create_sample_config()\n",
    "print(\"‚úì Sample configuration created!\")\n",
    "\n",
    "# Display the configuration\n",
    "if os.path.exists(\"sample_config.json\"):\n",
    "    with open(\"sample_config.json\", 'r') as f:\n",
    "        config = json.load(f)\n",
    "    print(\"\\nCurrent configuration:\")\n",
    "    print(json.dumps(config, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Mode\n",
    "\n",
    "Run single node or distributed training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single node training\n",
    "print(\"üöÄ Starting single node training...\")\n",
    "args.distributed = False\n",
    "\n",
    "try:\n",
    "    run_training_mode(args)\n",
    "    print(\"‚úÖ Training completed successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Training failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distributed training (uncomment to run)\n",
    "# print(\"üöÄ Starting distributed training...\")\n",
    "# args.distributed = True\n",
    "\n",
    "# try:\n",
    "#     run_training_mode(args)\n",
    "#     print(\"‚úÖ Distributed training completed successfully!\")\n",
    "# except Exception as e:\n",
    "#     print(f\"‚ùå Distributed training failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Mode\n",
    "\n",
    "Run single experiments or multiple iterations with statistical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single experiment\n",
    "print(\"üß™ Running single experiment...\")\n",
    "args.experiment_type = \"single\"\n",
    "\n",
    "try:\n",
    "    run_experiment_mode(args)\n",
    "    print(\"‚úÖ Single experiment completed successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Single experiment failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-20 14:19:36 - root - INFO - Starting experiment mode: multiple\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Running multiple experiments...\n",
      "FILES IN THIS DIRECTORY\n",
      "['DDP_KBIT', 'jars', 'config.json', 'mnist_pb2.py', 'spark_DL_checkpoints', 'sample_config.json']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/08/20 14:19:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/08/20 14:19:38 WARN ResourceUtils: The configuration of cores (exec = 5 task = 1, runnable tasks = 5) will result in wasted resources due to resource gpu limiting the number of runnable tasks per executor to: 1. Please adjust your configuration.\n",
      "25/08/20 14:19:39 WARN RapidsPluginUtils: RAPIDS Accelerator 24.06.1 using cudf 24.06.0, private revision 755b4dd03c753cacb7d141f3b3c8ff9f83888b69\n",
      "25/08/20 14:19:39 WARN RapidsPluginUtils: spark.rapids.sql.multiThreadedRead.numThreads is set to 20.\n",
      "25/08/20 14:19:39 WARN RapidsPluginUtils: The current setting of spark.task.resource.gpu.amount (1.0) is not ideal to get the best performance from the RAPIDS Accelerator plugin. It's recommended to be 1/{executor core count} unless you have a special use case.\n",
      "25/08/20 14:19:39 WARN RapidsPluginUtils: RAPIDS Accelerator is enabled, to disable GPU support set `spark.rapids.sql.enabled` to false.\n",
      "25/08/20 14:19:39 WARN RapidsPluginUtils: spark.rapids.sql.explain is set to `NOT_ON_GPU`. Set it to 'NONE' to suppress the diagnostics logging about the query placement on the GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Spark configuration:\n",
      "spark.app.id = app-20250820141939-0063\n",
      "spark.app.initial.file.urls = spark://192.168.141.56:39337/files/mnist_pb2.py\n",
      "spark.app.initial.jar.urls = spark://192.168.141.56:39337/jars/jsr305-3.0.0.jar,spark://192.168.141.56:39337/jars/spark-sql-kafka-0-10_2.12-3.5.1.jar,spark://192.168.141.56:39337/jars/commons-pool2-2.11.1.jar,spark://192.168.141.56:39337/jars/rapids-4-spark_2.12-24.06.1.jar,spark://192.168.141.56:39337/jars/commons-logging-1.1.3.jar,spark://192.168.141.56:39337/jars/spark-token-provider-kafka-0-10_2.12-3.5.1.jar,spark://192.168.141.56:39337/jars/hadoop-client-runtime-3.3.4.jar,spark://192.168.141.56:39337/jars/lz4-java-1.8.0.jar,spark://192.168.141.56:39337/jars/kafka-clients-3.4.1.jar,spark://192.168.141.56:39337/jars/spark-streaming-kafka-0-10_2.12-3.5.1.jar,spark://192.168.141.56:39337/jars/slf4j-api-2.0.7.jar,spark://192.168.141.56:39337/jars/snappy-java-1.1.10.3.jar,spark://192.168.141.56:39337/jars/hadoop-client-api-3.3.4.jar\n",
      "spark.app.name = DDP_KBIT_Experiments\n",
      "spark.app.startTime = 1755699578920\n",
      "spark.app.submitTime = 1755699578675\n",
      "spark.defaul.parallelism = 30\n",
      "spark.default.parallelism = 64\n",
      "spark.driver.extraJavaOptions = -Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false\n",
      "spark.driver.host = 192.168.141.56\n",
      "spark.driver.port = 39337\n",
      "spark.executor.cores = 5\n",
      "spark.executor.extraJavaOptions = -Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false\n",
      "spark.executor.id = driver\n",
      "spark.executor.instances = 3\n",
      "spark.executor.memory = 24g\n",
      "spark.executor.resource.gpu.amount = 1\n",
      "spark.executor.resource.gpu.discoveryScript = /opt/spark/conf/getGpusResources.sh\n",
      "spark.files = file:///mnt/data/mnist_pb2.py\n",
      "spark.jars = jars/commons-logging-1.1.3.jar,jars/commons-pool2-2.11.1.jar,jars/hadoop-client-api-3.3.4.jar,jars/hadoop-client-runtime-3.3.4.jar,jars/jsr305-3.0.0.jar,jars/kafka-clients-3.4.1.jar,jars/lz4-java-1.8.0.jar,jars/slf4j-api-2.0.7.jar,jars/snappy-java-1.1.10.3.jar,jars/spark-sql-kafka-0-10_2.12-3.5.1.jar,jars/spark-streaming-kafka-0-10_2.12-3.5.1.jar,jars/spark-token-provider-kafka-0-10_2.12-3.5.1.jar,jars/rapids-4-spark_2.12-24.06.1.jar\n",
      "spark.master = spark://spark-master-service:7077\n",
      "spark.plugins = com.nvidia.spark.SQLPlugin\n",
      "spark.plugins.internal.conf.com.nvidia.spark.SQLPlugin.spark.rapids.driver.user.timezone = Z\n",
      "spark.plugins.internal.conf.com.nvidia.spark.SQLPlugin.spark.rapids.memory.gpu.minAllocFraction = 0.1\n",
      "spark.plugins.internal.conf.com.nvidia.spark.SQLPlugin.spark.rapids.memory.pinnedPool.size = 2g\n",
      "spark.plugins.internal.conf.com.nvidia.spark.SQLPlugin.spark.rapids.sql.concurrentGpuTasks = 1\n",
      "spark.plugins.internal.conf.com.nvidia.spark.SQLPlugin.spark.rapids.sql.multiThreadedRead.numThreads = 20\n",
      "spark.rapids.driver.user.timezone = Z\n",
      "spark.rapids.memory.gpu.minAllocFraction = 0.1\n",
      "spark.rapids.memory.pinnedPool.size = 2g\n",
      "spark.rapids.sql.concurrentGpuTasks = 1\n",
      "spark.rapids.sql.multiThreadedRead.numThreads = 20\n",
      "spark.rdd.compress = True\n",
      "spark.repl.local.jars = file:///mnt/data/jars/commons-logging-1.1.3.jar,file:///mnt/data/jars/commons-pool2-2.11.1.jar,file:///mnt/data/jars/hadoop-client-api-3.3.4.jar,file:///mnt/data/jars/hadoop-client-runtime-3.3.4.jar,file:///mnt/data/jars/jsr305-3.0.0.jar,file:///mnt/data/jars/kafka-clients-3.4.1.jar,file:///mnt/data/jars/lz4-java-1.8.0.jar,file:///mnt/data/jars/slf4j-api-2.0.7.jar,file:///mnt/data/jars/snappy-java-1.1.10.3.jar,file:///mnt/data/jars/spark-sql-kafka-0-10_2.12-3.5.1.jar,file:///mnt/data/jars/spark-streaming-kafka-0-10_2.12-3.5.1.jar,file:///mnt/data/jars/spark-token-provider-kafka-0-10_2.12-3.5.1.jar,file:///mnt/data/jars/rapids-4-spark_2.12-24.06.1.jar\n",
      "spark.serializer.objectStreamReset = 100\n",
      "spark.sql.extensions = com.nvidia.spark.rapids.SQLExecPlugin,com.nvidia.spark.udf.Plugin,com.nvidia.spark.rapids.optimizer.SQLOptimizerPlugin\n",
      "spark.sql.shuffle.partitions = 30\n",
      "spark.submit.deployMode = client\n",
      "spark.submit.pyFiles = mnist_pb2.py\n",
      "spark.task.resource.gpu.amount = 1\n",
      "spark.ui.showConsoleProgress = true\n",
      "Starting 5 iterations of experiments...\n",
      "\n",
      "==================================================\n",
      "Ïã§Ìóò Î∞òÎ≥µ 1/5\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-20 14:19:42 - TorchDistributor - INFO - Started distributed training with 3 executor processes\n",
      "2025-08-20 14:19:43 - numexpr.utils - INFO - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2025-08-20 14:19:43 - numexpr.utils - INFO - NumExpr defaulting to 8 threads.\n",
      "/usr/local/lib/python3.9/dist-packages/ignite/handlers/checkpoint.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
      "/usr/local/lib/python3.9/dist-packages/ignite/handlers/checkpoint.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
      "Warning: config.json not found. Using default values.\n",
      "Warning: config.json not found. Using default values.\n",
      "/usr/local/lib/python3.9/dist-packages/ignite/handlers/checkpoint.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
      "Warning: config.json not found. Using default values.\n",
      "/usr/local/lib/python3.9/dist-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "Running data loading experiment with 4 configurations\n",
      "/usr/local/lib/python3.9/dist-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "Running data loading experiment with 4 configurations\n",
      "/usr/local/lib/python3.9/dist-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "Running data loading experiment with 4 configurations\n",
      "[PID 9844] world_size = 3, global_rank = 2, local_rank = 0\n",
      "RANK[2] Ïã§Ìóò: avro_lz4, ÌÜ†ÌîΩ: my-topic-4\n",
      "Rank 2: API URL = http://155.230.36.25:3001/data/export/?connection_id=my-mongo-1&mongo_database=kbit-db&collection=mnist_train_avro&kafka_brokers=155.230.35.200%3A32100%2C155.230.35.213%3A32100%2C155.230.35.215%3A32100&send_topic=kbit-p3r1\n",
      "[PID 9580] world_size = 3, global_rank = 0, local_rank = 0\n",
      "\n",
      "===== avro_lz4 Ïã§Ìóò ÏãúÏûë =====\n",
      "RANK[0] Ïã§Ìóò: avro_lz4, ÌÜ†ÌîΩ: my-topic-4\n",
      "Rank 0: API URL = http://155.230.36.25:3001/data/export/?connection_id=my-mongo-1&mongo_database=kbit-db&collection=mnist_train_avro&kafka_brokers=155.230.35.200%3A32100%2C155.230.35.213%3A32100%2C155.230.35.215%3A32100&send_topic=kbit-p3r1\n",
      "[PID 9402] world_size = 3, global_rank = 1, local_rank = 0\n",
      "RANK[1] Ïã§Ìóò: avro_lz4, ÌÜ†ÌîΩ: my-topic-4\n",
      "Rank 1: API URL = http://155.230.36.25:3001/data/export/?connection_id=my-mongo-1&mongo_database=kbit-db&collection=mnist_train_avro&kafka_brokers=155.230.35.200%3A32100%2C155.230.35.213%3A32100%2C155.230.35.215%3A32100&send_topic=kbit-p3r1\n",
      "Rank 2 Polling:   0%|          | 0/17142 [00:00<?, ?msg/s]Rank 2 : Î©îÏÑ∏ÏßÄ Polling Start 0 ~ 17141\n",
      "Rank 0 Polling:   0%|          | 0/17142 [00:00<?, ?msg/s]Rank 0 : Î©îÏÑ∏ÏßÄ Polling Start 0 ~ 17141\n",
      "Rank 1 Polling:   0%|          | 0/17142 [00:00<?, ?msg/s]Rank 1 : Î©îÏÑ∏ÏßÄ Polling Start 0 ~ 17141\n",
      "Rank 0 Polling:   0%|          | 1/17142 [00:00<57:35,  4.96msg/s]\n",
      "Rank 2 Polling:   0%|          | 1/17142 [00:00<1:05:14,  4.38msg/s]\n",
      "Rank 0 Polling:   0%|          | 0/1429 [00:00<?, ?msg/s]Rank 0 : Î©îÏÑ∏ÏßÄ Polling Start 17142 ~ 18570\n",
      "Rank 1 Polling:   0%|          | 1/17142 [00:00<1:38:39,  2.90msg/s]\n",
      "Rank 2 Polling:   0%|          | 0/1429 [00:00<?, ?msg/s]Rank 2 : Î©îÏÑ∏ÏßÄ Polling Start 17142 ~ 18570\n",
      "Rank 0 Polling:   0%|          | 1/1429 [00:00<00:55, 25.74msg/s]\n",
      "Rank 0 Polling:   0%|          | 0/1429 [00:00<?, ?msg/s]Rank 0 : Î©îÏÑ∏ÏßÄ Polling Start 18571 ~ 19999\n",
      "Rank 1 Polling:   0%|          | 0/1429 [00:00<?, ?msg/s]Rank 1 : Î©îÏÑ∏ÏßÄ Polling Start 17142 ~ 18570\n",
      "Rank 2 Polling:   0%|          | 1/1429 [00:00<04:50,  4.92msg/s]\n",
      "Rank 2 Polling:   0%|          | 0/1429 [00:00<?, ?msg/s]Rank 2 : Î©îÏÑ∏ÏßÄ Polling Start 18571 ~ 19999\n",
      "Rank 0 Polling:   0%|          | 1/1429 [00:00<04:41,  5.08msg/s]\n",
      "Rank 0: Data size after sampling: 1429\n",
      "Rank 0: Creating DataLoader with batch size 10\n",
      "Rank 1 Polling:   0%|          | 1/1429 [00:00<07:58,  2.99msg/s]\n",
      "Rank 2 Polling:   0%|          | 1/1429 [00:00<05:32,  4.30msg/s]\n",
      "Rank 2: Data size after sampling: 1429\n",
      "Rank 2: Creating DataLoader with batch size 10\n",
      "Rank 1 Polling:   0%|          | 0/1429 [00:00<?, ?msg/s]Rank 1 : Î©îÏÑ∏ÏßÄ Polling Start 18571 ~ 19999\n",
      "Rank 1 Polling:   0%|          | 1/1429 [00:00<07:08,  3.34msg/s]\n",
      "Rank 1: Data size after sampling: 1429\n",
      "Rank 1: Creating DataLoader with batch size 10\n",
      "Î™®Îì† RankÏùò Îç∞Ïù¥ÌÑ∞ Î°úÎî© ÏãúÍ∞Ñ: ['0.769Ï¥à', '1.313Ï¥à', '0.996Ï¥à']\n",
      "Í∞Å RankÎ≥Ñ Î∞∞Ïπò Ï†ïÎ≥¥:\n",
      "Rank 0: Train=1, Val=1, Test=143\n",
      "Rank 1: Train=1, Val=1, Test=143\n",
      "Rank 2: Train=1, Val=1, Test=143\n",
      "avro_lz4 - ÌèâÍ∑†: 1.03Ï¥à, ÏµúÏÜå: 0.77Ï¥à, ÏµúÎåÄ: 1.31Ï¥à\n",
      "RANK[2] Ïã§Ìóò: avro_none, ÌÜ†ÌîΩ: my-topic-5\n",
      "Rank 2: API URL = http://155.230.36.25:3001/data/export/?connection_id=my-mongo-1&mongo_database=kbit-db&collection=mnist_train_avro&kafka_brokers=155.230.35.200%3A32100%2C155.230.35.213%3A32100%2C155.230.35.215%3A32100&send_topic=kbit-p3r1\n",
      "\n",
      "===== avro_none Ïã§Ìóò ÏãúÏûë =====\n",
      "RANK[0] Ïã§Ìóò: avro_none, ÌÜ†ÌîΩ: my-topic-5\n",
      "Rank 0: API URL = http://155.230.36.25:3001/data/export/?connection_id=my-mongo-1&mongo_database=kbit-db&collection=mnist_train_avro&kafka_brokers=155.230.35.200%3A32100%2C155.230.35.213%3A32100%2C155.230.35.215%3A32100&send_topic=kbit-p3r1\n",
      "RANK[1] Ïã§Ìóò: avro_none, ÌÜ†ÌîΩ: my-topic-5\n",
      "Rank 1: API URL = http://155.230.36.25:3001/data/export/?connection_id=my-mongo-1&mongo_database=kbit-db&collection=mnist_train_avro&kafka_brokers=155.230.35.200%3A32100%2C155.230.35.213%3A32100%2C155.230.35.215%3A32100&send_topic=kbit-p3r1\n",
      "Rank 2 Polling:   0%|          | 0/17142 [00:00<?, ?msg/s]Rank 2 : Î©îÏÑ∏ÏßÄ Polling Start 0 ~ 17141\n",
      "Rank 0 Polling:   0%|          | 0/17142 [00:00<?, ?msg/s]Rank 0 : Î©îÏÑ∏ÏßÄ Polling Start 0 ~ 17141\n",
      "Rank 1 Polling:   0%|          | 0/17142 [00:00<?, ?msg/s]Rank 1 : Î©îÏÑ∏ÏßÄ Polling Start 0 ~ 17141\n",
      "Rank 2 : 0 ~ 17141 polling Timeout... try again\n",
      "Rank 2 Polling:   0%|          | 0/17142 [00:03<?, ?msg/s]\n",
      "Rank 0 : 0 ~ 17141 polling Timeout... try again\n",
      "Rank 0 Polling:   0%|          | 0/17142 [00:03<?, ?msg/s]\n",
      "Rank 1 : 0 ~ 17141 polling Timeout... try again\n",
      "Rank 1 Polling:   0%|          | 0/17142 [00:03<?, ?msg/s]\n",
      "Rank 2 Polling:   0%|          | 0/1429 [00:00<?, ?msg/s]Rank 2 : Î©îÏÑ∏ÏßÄ Polling Start 17142 ~ 18570\n",
      "Rank 0 Polling:   0%|          | 0/1429 [00:00<?, ?msg/s]Rank 0 : Î©îÏÑ∏ÏßÄ Polling Start 17142 ~ 18570\n",
      "Rank 1 Polling:   0%|          | 0/1429 [00:00<?, ?msg/s]Rank 1 : Î©îÏÑ∏ÏßÄ Polling Start 17142 ~ 18570\n",
      "Rank 2 : 17142 ~ 18570 polling Timeout... try again\n",
      "Rank 2 Polling:   0%|          | 0/1429 [00:03<?, ?msg/s]\n",
      "Rank 0 : 17142 ~ 18570 polling Timeout... try again\n",
      "Rank 0 Polling:   0%|          | 0/1429 [00:03<?, ?msg/s]\n",
      "Rank 1 : 17142 ~ 18570 polling Timeout... try again\n",
      "Rank 1 Polling:   0%|          | 0/1429 [00:03<?, ?msg/s]\n",
      "Rank 2 Polling:   0%|          | 0/1429 [00:00<?, ?msg/s]Rank 2 : Î©îÏÑ∏ÏßÄ Polling Start 18571 ~ 19999\n",
      "Rank 0 Polling:   0%|          | 0/1429 [00:00<?, ?msg/s]Rank 0 : Î©îÏÑ∏ÏßÄ Polling Start 18571 ~ 19999\n",
      "Rank 1 Polling:   0%|          | 0/1429 [00:00<?, ?msg/s]Rank 1 : Î©îÏÑ∏ÏßÄ Polling Start 18571 ~ 19999\n",
      "Rank 2 : 18571 ~ 19999 polling Timeout... try again\n",
      "Rank 2 Polling:   0%|          | 0/1429 [00:03<?, ?msg/s]\n",
      "[rank2]: Traceback (most recent call last):\n",
      "[rank2]:   File \"/tmp/tmp_b7jxp3j/train.py\", line 8, in <module>\n",
      "[rank2]:     output = train_fn(*args, **kwargs)\n",
      "[rank2]:   File \"/usr/local/lib/python3.9/dist-packages/ddp_kbit/experiments/runner.py\", line 293, in exp_fn\n",
      "[rank2]:     splited_datasets = DistributedDataFetcher(current_data_loader_config, device=init_config[\"device\"]) \\\n",
      "[rank2]:   File \"/usr/local/lib/python3.9/dist-packages/ddp_kbit/experiments/runner.py\", line 79, in fetch_n_pull_splited_datasets\n",
      "[rank2]:     datasets = self._create_datasets(offset_ranges, send_topic)\n",
      "[rank2]:   File \"/usr/local/lib/python3.9/dist-packages/ddp_kbit/experiments/runner.py\", line 104, in _create_datasets\n",
      "[rank2]:     dataset = DistributedDataset(\n",
      "[rank2]:   File \"/usr/local/lib/python3.9/dist-packages/ddp_kbit/data/datasets.py\", line 80, in __init__\n",
      "[rank2]:     self.data = self._load_data()\n",
      "[rank2]:   File \"/usr/local/lib/python3.9/dist-packages/ddp_kbit/data/datasets.py\", line 98, in _load_data\n",
      "[rank2]:     data.extend(random.choices(data, k=max_offset_diff + 1 - len(data)))\n",
      "[rank2]:   File \"/usr/lib/python3.9/random.py\", line 487, in choices\n",
      "[rank2]:     return [population[floor(random() * n)] for i in _repeat(None, k)]\n",
      "[rank2]:   File \"/usr/lib/python3.9/random.py\", line 487, in <listcomp>\n",
      "[rank2]:     return [population[floor(random() * n)] for i in _repeat(None, k)]\n",
      "[rank2]: IndexError: list index out of range\n",
      "Rank 0 : 18571 ~ 19999 polling Timeout... try again\n",
      "Rank 0 Polling:   0%|          | 0/1429 [00:03<?, ?msg/s]\n",
      "[rank0]: Traceback (most recent call last):\n",
      "[rank0]:   File \"/tmp/tmpte9h1a2r/train.py\", line 8, in <module>\n",
      "[rank0]:     output = train_fn(*args, **kwargs)\n",
      "[rank0]:   File \"/usr/local/lib/python3.9/dist-packages/ddp_kbit/experiments/runner.py\", line 293, in exp_fn\n",
      "[rank0]:     splited_datasets = DistributedDataFetcher(current_data_loader_config, device=init_config[\"device\"]) \\\n",
      "[rank0]:   File \"/usr/local/lib/python3.9/dist-packages/ddp_kbit/experiments/runner.py\", line 79, in fetch_n_pull_splited_datasets\n",
      "[rank0]:     datasets = self._create_datasets(offset_ranges, send_topic)\n",
      "[rank0]:   File \"/usr/local/lib/python3.9/dist-packages/ddp_kbit/experiments/runner.py\", line 104, in _create_datasets\n",
      "[rank0]:     dataset = DistributedDataset(\n",
      "[rank0]:   File \"/usr/local/lib/python3.9/dist-packages/ddp_kbit/data/datasets.py\", line 80, in __init__\n",
      "[rank0]:     self.data = self._load_data()\n",
      "[rank0]:   File \"/usr/local/lib/python3.9/dist-packages/ddp_kbit/data/datasets.py\", line 98, in _load_data\n",
      "[rank0]:     data.extend(random.choices(data, k=max_offset_diff + 1 - len(data)))\n",
      "[rank0]:   File \"/usr/lib/python3.9/random.py\", line 487, in choices\n",
      "[rank0]:     return [population[floor(random() * n)] for i in _repeat(None, k)]\n",
      "[rank0]:   File \"/usr/lib/python3.9/random.py\", line 487, in <listcomp>\n",
      "[rank0]:     return [population[floor(random() * n)] for i in _repeat(None, k)]\n",
      "[rank0]: IndexError: list index out of range\n",
      "Rank 1 : 18571 ~ 19999 polling Timeout... try again\n",
      "Rank 1 Polling:   0%|          | 0/1429 [00:03<?, ?msg/s]\n",
      "[rank1]: Traceback (most recent call last):\n",
      "[rank1]:   File \"/tmp/tmps85k21xk/train.py\", line 8, in <module>\n",
      "[rank1]:     output = train_fn(*args, **kwargs)\n",
      "[rank1]:   File \"/usr/local/lib/python3.9/dist-packages/ddp_kbit/experiments/runner.py\", line 293, in exp_fn\n",
      "[rank1]:     splited_datasets = DistributedDataFetcher(current_data_loader_config, device=init_config[\"device\"]) \\\n",
      "[rank1]:   File \"/usr/local/lib/python3.9/dist-packages/ddp_kbit/experiments/runner.py\", line 79, in fetch_n_pull_splited_datasets\n",
      "[rank1]:     datasets = self._create_datasets(offset_ranges, send_topic)\n",
      "[rank1]:   File \"/usr/local/lib/python3.9/dist-packages/ddp_kbit/experiments/runner.py\", line 104, in _create_datasets\n",
      "[rank1]:     dataset = DistributedDataset(\n",
      "[rank1]:   File \"/usr/local/lib/python3.9/dist-packages/ddp_kbit/data/datasets.py\", line 80, in __init__\n",
      "[rank1]:     self.data = self._load_data()\n",
      "[rank1]:   File \"/usr/local/lib/python3.9/dist-packages/ddp_kbit/data/datasets.py\", line 98, in _load_data\n",
      "[rank1]:     data.extend(random.choices(data, k=max_offset_diff + 1 - len(data)))\n",
      "[rank1]:   File \"/usr/lib/python3.9/random.py\", line 487, in choices\n",
      "[rank1]:     return [population[floor(random() * n)] for i in _repeat(None, k)]\n",
      "[rank1]:   File \"/usr/lib/python3.9/random.py\", line 487, in <listcomp>\n",
      "[rank1]:     return [population[floor(random() * n)] for i in _repeat(None, k)]\n",
      "[rank1]: IndexError: list index out of range\n",
      "[rank0]:[W820 14:20:20.796165820 ProcessGroupNCCL.cpp:1168] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())\n",
      "[rank1]:[W820 14:20:20.423113320 ProcessGroupNCCL.cpp:1168] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())\n",
      "[rank2]:[W820 14:20:20.364914120 ProcessGroupNCCL.cpp:1168] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())\n",
      "E0820 14:20:21.689090 140563450267456 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 0 (pid: 9844) of binary: /usr/bin/python3\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/run.py\", line 905, in <module>\n",
      "    main()\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 348, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/run.py\", line 901, in main\n",
      "    run(args)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/run.py\", line 892, in run\n",
      "    elastic_launch(\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/launcher/api.py\", line 133, in __call__\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/launcher/api.py\", line 264, in launch_agent\n",
      "    raise ChildFailedError(\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError:\n",
      "============================================================\n",
      "/tmp/tmp_b7jxp3j/train.py FAILED\n",
      "------------------------------------------------------------\n",
      "Failures:\n",
      "  <NO_OTHER_FAILURES>\n",
      "------------------------------------------------------------\n",
      "Root Cause (first observed failure):\n",
      "[0]:\n",
      "  time      : 2025-08-20_14:20:21\n",
      "  host      : spark-worker-6455768c55-h44ld\n",
      "  rank      : 2 (local_rank: 0)\n",
      "  exitcode  : 1 (pid: 9844)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "============================================================\n",
      "E0820 14:20:21.720530 140123088537408 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 0 (pid: 9580) of binary: /usr/bin/python3\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/run.py\", line 905, in <module>\n",
      "    main()\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 348, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/run.py\", line 901, in main\n",
      "    run(args)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/run.py\", line 892, in run\n",
      "    elastic_launch(\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/launcher/api.py\", line 133, in __call__\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/launcher/api.py\", line 264, in launch_agent\n",
      "    raise ChildFailedError(\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError:\n",
      "============================================================\n",
      "/tmp/tmpte9h1a2r/train.py FAILED\n",
      "------------------------------------------------------------\n",
      "Failures:\n",
      "  <NO_OTHER_FAILURES>\n",
      "------------------------------------------------------------\n",
      "Root Cause (first observed failure):\n",
      "[0]:\n",
      "  time      : 2025-08-20_14:20:21\n",
      "  host      : spark-worker-6455768c55-xzg5w\n",
      "  rank      : 0 (local_rank: 0)\n",
      "E0820 14:20:21.706110 139694116214592 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 0 (pid: 9402) of binary: /usr/bin/python3\n",
      "  exitcode  : 1 (pid: 9580)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "============================================================\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/run.py\", line 905, in <module>\n",
      "    main()\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 348, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/run.py\", line 901, in main\n",
      "    run(args)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/run.py\", line 892, in run\n",
      "    elastic_launch(\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/launcher/api.py\", line 133, in __call__\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/launcher/api.py\", line 264, in launch_agent\n",
      "    raise ChildFailedError(\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError:\n",
      "============================================================\n",
      "/tmp/tmps85k21xk/train.py FAILED\n",
      "------------------------------------------------------------\n",
      "Failures:\n",
      "  <NO_OTHER_FAILURES>\n",
      "------------------------------------------------------------\n",
      "Root Cause (first observed failure):\n",
      "[0]:\n",
      "  time      : 2025-08-20_14:20:21\n",
      "  host      : spark-worker-6455768c55-kxnb6\n",
      "  rank      : 1 (local_rank: 0)\n",
      "  exitcode  : 1 (pid: 9402)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "============================================================\n",
      "2025-08-20 14:20:22 - root - ERROR - Experiments failed: An error occurred while calling o216.collectToPython.\n",
      ": org.apache.spark.SparkException: Job aborted due to stage failure: Could not recover from a failed barrier ResultStage. Most recent failure reason: Stage failed because barrier task ResultTask(0, 1) finished unsuccessfully.\n",
      "org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/pyspark/ml/torch/distributor.py\", line 732, in wrapped_train_fn\n",
      "  File \"/opt/spark/python/lib/pyspark.zip/pyspark/ml/torch/distributor.py\", line 566, in _get_output_from_framework_wrapper\n",
      "    return framework_wrapper(\n",
      "  File \"/opt/spark/python/lib/pyspark.zip/pyspark/ml/torch/distributor.py\", line 914, in _run_training_on_pytorch_function\n",
      "    raise RuntimeError(\n",
      "RuntimeError: TorchDistributor failed during training.View stdout logs for detailed error message.\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n",
      "\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:118)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:2228)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3054)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2463)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1049)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:410)\n",
      "\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1048)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:448)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$collectToPython$1(Dataset.scala:4148)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4322)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4320)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:4320)\n",
      "\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:4145)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Multiple experiments failed: An error occurred while calling o216.collectToPython.\n",
      ": org.apache.spark.SparkException: Job aborted due to stage failure: Could not recover from a failed barrier ResultStage. Most recent failure reason: Stage failed because barrier task ResultTask(0, 1) finished unsuccessfully.\n",
      "org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/pyspark/ml/torch/distributor.py\", line 732, in wrapped_train_fn\n",
      "  File \"/opt/spark/python/lib/pyspark.zip/pyspark/ml/torch/distributor.py\", line 566, in _get_output_from_framework_wrapper\n",
      "    return framework_wrapper(\n",
      "  File \"/opt/spark/python/lib/pyspark.zip/pyspark/ml/torch/distributor.py\", line 914, in _run_training_on_pytorch_function\n",
      "    raise RuntimeError(\n",
      "RuntimeError: TorchDistributor failed during training.View stdout logs for detailed error message.\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n",
      "\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:118)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:2228)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3054)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2463)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1049)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:410)\n",
      "\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1048)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:448)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$collectToPython$1(Dataset.scala:4148)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4322)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4320)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:4320)\n",
      "\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:4145)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Multiple experiments with statistical analysis\n",
    "print(\"üß™ Running multiple experiments...\")\n",
    "args.experiment_type = \"multiple\"\n",
    "args.iterations = 5  # You can change this number\n",
    "\n",
    "try:\n",
    "    run_experiment_mode(args)\n",
    "    print(f\"‚úÖ {args.iterations} experiments completed successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Multiple experiments failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions\n",
    "\n",
    "Helper functions for notebook usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_train(distributed=False, config_path=\"sample_config.json\"):\n",
    "    \"\"\"Quick training function for easy execution.\"\"\"\n",
    "    args.distributed = distributed\n",
    "    args.config_path = config_path\n",
    "    \n",
    "    print(f\"üöÄ Quick training - Distributed: {distributed}\")\n",
    "    try:\n",
    "        run_training_mode(args)\n",
    "        print(\"‚úÖ Training completed!\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Training failed: {e}\")\n",
    "\n",
    "def quick_experiment(experiment_type=\"single\", iterations=3):\n",
    "    \"\"\"Quick experiment function for easy execution.\"\"\"\n",
    "    args.experiment_type = experiment_type\n",
    "    args.iterations = iterations\n",
    "    \n",
    "    print(f\"üß™ Quick experiment - Type: {experiment_type}, Iterations: {iterations}\")\n",
    "    try:\n",
    "        run_experiment_mode(args)\n",
    "        print(\"‚úÖ Experiment completed!\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Experiment failed: {e}\")\n",
    "\n",
    "print(\"‚úì Utility functions loaded!\")\n",
    "print(\"\\nUse these functions for quick execution:\")\n",
    "print(\"- quick_train(distributed=False)\")\n",
    "print(\"- quick_experiment(experiment_type='multiple', iterations=5)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Execution Examples\n",
    "\n",
    "Use the utility functions for quick execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Quick single training\n",
    "# quick_train()\n",
    "\n",
    "# Example: Quick multiple experiments\n",
    "# quick_experiment(experiment_type=\"multiple\", iterations=3)\n",
    "\n",
    "print(\"üí° Uncomment the lines above to run quick examples!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
