# DDP_KBIT ì„¤ì¹˜ ë° ì‚¬ìš© ê°€ì´ë“œ

## ğŸ“‹ ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­

### í•„ìˆ˜ ìš”êµ¬ì‚¬í•­
- **Python**: 3.8 ì´ìƒ
- **ìš´ì˜ì²´ì œ**: Windows 10/11, Linux, macOS
- **ë©”ëª¨ë¦¬**: ìµœì†Œ 8GB RAM (16GB ê¶Œì¥)
- **ì €ì¥ê³µê°„**: ìµœì†Œ 5GB ì—¬ìœ  ê³µê°„

### ì„ íƒì  ìš”êµ¬ì‚¬í•­
- **GPU**: CUDA 11.0 ì´ìƒ ì§€ì› GPU (NVIDIA)
- **Apache Kafka**: ì‹¤ì‹œê°„ ë°ì´í„° ìŠ¤íŠ¸ë¦¬ë°ìš©
- **Apache Spark**: ë¶„ì‚° ì²˜ë¦¬ìš©

## ğŸš€ ì„¤ì¹˜ ë°©ë²•

### 1. ì†ŒìŠ¤ì½”ë“œ ë‹¤ìš´ë¡œë“œ
```bash
# Gitì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš°
git clone <repository-url>
cd DDP_KBIT

# ë˜ëŠ” ì••ì¶• íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ì••ì¶• í•´ì œ
```

### 2. ê°€ìƒí™˜ê²½ ìƒì„± (ê¶Œì¥)
```bash
# Python venv ì‚¬ìš©
python -m venv ddp_kbit_env

# Windowsì—ì„œ ê°€ìƒí™˜ê²½ í™œì„±í™”
ddp_kbit_env\Scripts\activate

# Linux/macOSì—ì„œ ê°€ìƒí™˜ê²½ í™œì„±í™”
source ddp_kbit_env/bin/activate
```

### 3. íŒ¨í‚¤ì§€ ì„¤ì¹˜
```bash
# ê°œë°œ ëª¨ë“œë¡œ ì„¤ì¹˜ (ì†ŒìŠ¤ì½”ë“œ ìˆ˜ì • ì‹œ ìë™ ë°˜ì˜)
pip install -e .

# ë˜ëŠ” ì˜ì¡´ì„±ë§Œ ì„¤ì¹˜
pip install -r requirements.txt
```

### 4. ì„¤ì¹˜ í™•ì¸
```bash
# íŒ¨í‚¤ì§€ ì„í¬íŠ¸ í…ŒìŠ¤íŠ¸
python -c "import DDP_KBIT; print('ì„¤ì¹˜ ì„±ê³µ!')"

# ëª…ë ¹ì¤„ ë„êµ¬ í™•ì¸
ddp-kbit --help
```

## ğŸ”§ ì´ˆê¸° ì„¤ì •

### 1. ìƒ˜í”Œ ì„¤ì • íŒŒì¼ ìƒì„±
```bash
ddp-kbit --create_sample_config
```

ì´ ëª…ë ¹ì€ `sample_config.json` íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.

### 2. ì„¤ì • íŒŒì¼ í¸ì§‘
ìƒì„±ëœ `sample_config.json` íŒŒì¼ì„ í¸ì§‘í•˜ì—¬ í™˜ê²½ì— ë§ê²Œ ì„¤ì •:

```json
{
  "spark_config": {
    "master": "local[*]",
    "app_name": "DDP_KBIT_Sample",
    "executor_instances": 2,
    "executor_cores": 2,
    "executor_memory": "4g"
  },
  "training_config": {
    "epochs": 5,
    "batch_size": 64,
    "learning_rate": 0.001
  },
  "data_config": {
    "kafka_servers": ["localhost:9092"],
    "topic": "mnist_topic",
    "batch_size": 32
  }
}
```

## ğŸ“š ì‚¬ìš©ë²•

### ê¸°ë³¸ ì‚¬ìš©ë²•

#### 1. í›ˆë ¨ ëª¨ë“œ
```bash
# ë‹¨ì¼ ë…¸ë“œ í›ˆë ¨
ddp-kbit --mode train --config_path sample_config.json

# ë¶„ì‚° í›ˆë ¨
ddp-kbit --mode train --distributed --config_path sample_config.json
```

#### 2. ì‹¤í—˜ ëª¨ë“œ
```bash
# ë‹¨ì¼ ì‹¤í—˜
ddp-kbit --mode experiment --experiment_type single

# ë‹¤ì¤‘ ì‹¤í—˜ (í†µê³„ ë¶„ì„ í¬í•¨)
ddp-kbit --mode experiment --experiment_type multiple --iterations 10
```

#### 3. ë„ì›€ë§ ë³´ê¸°
```bash
# ì „ì²´ ë„ì›€ë§
ddp-kbit --help

# íŠ¹ì • ëª¨ë“œ ë„ì›€ë§
ddp-kbit --mode train --help
ddp-kbit --mode experiment --help
```

### Python ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ì‚¬ìš©

#### 1. ê¸°ë³¸ ì„í¬íŠ¸
```python
from DDP_KBIT.main import run_training_mode, run_experiment_mode
from DDP_KBIT.config import training_config, data_config, spark_config
```

#### 2. í›ˆë ¨ ì‹¤í–‰
```python
# ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ í›ˆë ¨ ì‹¤í–‰
run_training_mode(None)

# ë˜ëŠ” ì„¤ì • ê°ì²´ ìƒì„±
class Args:
    def __init__(self):
        self.config_path = "my_config.json"
        self.distributed = True

args = Args()
run_training_mode(args)
```

#### 3. ì‹¤í—˜ ì‹¤í–‰
```python
# ë‹¨ì¼ ì‹¤í—˜
run_experiment_mode(None)

# ë‹¤ì¤‘ ì‹¤í—˜
class Args:
    def __init__(self):
        self.experiment_type = "multiple"
        self.iterations = 20

args = Args()
run_experiment_mode(args)
```

### Jupyter Notebookì—ì„œ ì‚¬ìš©

#### 1. ë…¸íŠ¸ë¶ ì¸í„°í˜ì´ìŠ¤ ì‚¬ìš©
```python
# DDP_KBIT ë…¸íŠ¸ë¶ ì¸í„°í˜ì´ìŠ¤ ì„í¬íŠ¸
from DDP_KBIT.notebook_interface import setup_module_path, run_training_mode

# ëª¨ë“ˆ ê²½ë¡œ ì„¤ì •
setup_module_path()

# í›ˆë ¨ ì‹¤í–‰
run_training_mode(None)
```

#### 2. ì§ì ‘ ëª¨ë“ˆ ì‚¬ìš©
```python
# í•„ìš”í•œ ëª¨ë“ˆë“¤ ì„í¬íŠ¸
from DDP_KBIT.models.networks import create_cnn_model
from DDP_KBIT.training.trainer import main_fn
from DDP_KBIT.utils.spark_utils import create_spark_session

# Spark ì„¸ì…˜ ìƒì„±
spark = create_spark_session(app_name="My_Notebook_App")

# ëª¨ë¸ ìƒì„±
model = create_cnn_model()
```

## ğŸ” ë¬¸ì œ í•´ê²°

### ì¼ë°˜ì ì¸ ë¬¸ì œë“¤

#### 1. ì„í¬íŠ¸ ì˜¤ë¥˜
```bash
# ì˜¤ë¥˜: ModuleNotFoundError: No module named 'DDP_KBIT'
# í•´ê²°: íŒ¨í‚¤ì§€ê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì¹˜ë˜ì—ˆëŠ”ì§€ í™•ì¸
pip list | grep DDP_KBIT

# ì¬ì„¤ì¹˜
pip uninstall ddp-kbit
pip install -e .
```

#### 2. CUDA ë©”ëª¨ë¦¬ ë¶€ì¡±
```bash
# ì„¤ì • íŒŒì¼ì—ì„œ ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸°
"batch_size": 32  # 64ì—ì„œ 32ë¡œ ì¤„ì´ê¸°

# ë˜ëŠ” GPU ì‚¬ìš© ë¹„í™œì„±í™”
"use_gpu": false
```

#### 3. Spark ì„¤ì • ì˜¤ë¥˜
```bash
# ë¡œì»¬ ëª¨ë“œë¡œ ì‹¤í–‰
"master": "local[*]"

# ë©”ëª¨ë¦¬ ì„¤ì • ì¡°ì •
"executor_memory": "2g"  # 4gì—ì„œ 2gë¡œ ì¤„ì´ê¸°
```

#### 4. Kafka ì—°ê²° ì˜¤ë¥˜
```bash
# Kafka ì„œë²„ ì£¼ì†Œ í™•ì¸
"kafka_servers": ["localhost:9092"]

# ë˜ëŠ” Kafka ì—†ì´ ì‹¤í–‰ (ë¡œì»¬ ë°ì´í„° ì‚¬ìš©)
```

### ë¡œê·¸ ë ˆë²¨ ì¡°ì •
```bash
# ë””ë²„ê·¸ ì •ë³´ ë³´ê¸°
ddp-kbit --mode train --log_level DEBUG

# ê²½ê³ ë§Œ ë³´ê¸°
ddp-kbit --mode train --log_level WARNING
```

## ğŸ“Š ì„±ëŠ¥ ìµœì í™”

### 1. GPU ê°€ì†
```bash
# CUDA ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
python -c "import torch; print(torch.cuda.is_available())"

# GPU ë©”ëª¨ë¦¬ í™•ì¸
nvidia-smi
```

### 2. Spark ì„¤ì • ìµœì í™”
```json
{
  "spark_config": {
    "executor_instances": 4,
    "executor_cores": 4,
    "executor_memory": "8g",
    "driver_memory": "4g"
  }
}
```

### 3. ë°°ì¹˜ í¬ê¸° ì¡°ì •
```json
{
  "training_config": {
    "batch_size": 128,  # GPU ë©”ëª¨ë¦¬ì— ë”°ë¼ ì¡°ì •
    "gradient_accumulation_steps": 2
  }
}
```

## ğŸ”§ ê³ ê¸‰ ì„¤ì •

### 1. ì‚¬ìš©ì ì •ì˜ ëª¨ë¸
```python
# models/networks.pyì— ìƒˆ ëª¨ë¸ ì¶”ê°€
class MyCustomModel(nn.Module):
    def __init__(self):
        super().__init__()
        # ëª¨ë¸ ì •ì˜
        
    def forward(self, x):
        # ìˆœì „íŒŒ ë¡œì§
        return x

# __init__.pyì— ë“±ë¡
__all__ = ['MyCustomModel', 'create_my_custom_model']
```

### 2. ì‚¬ìš©ì ì •ì˜ ë°ì´í„° ë³€í™˜
```python
# data/transforms.pyì— ìƒˆ ë³€í™˜ í•¨ìˆ˜ ì¶”ê°€
def my_custom_transform(data):
    # ë³€í™˜ ë¡œì§
    return transformed_data

# data_config.pyì— ë“±ë¡
CUSTOM_TRANSFORMS = {
    'my_transform': my_custom_transform
}
```

### 3. ì‚¬ìš©ì ì •ì˜ ì‹¤í—˜
```python
# experiments/runner.pyì— ìƒˆ ì‹¤í—˜ í•¨ìˆ˜ ì¶”ê°€
def my_custom_experiment():
    # ì‹¤í—˜ ë¡œì§
    return results

# main.pyì— ë“±ë¡
elif args.mode == "my_experiment":
    my_custom_experiment()
```

## ğŸ“ ê°œë°œ í™˜ê²½ ì„¤ì •

### 1. ê°œë°œ ì˜ì¡´ì„± ì„¤ì¹˜
```bash
pip install -r requirements.txt[dev]
```

### 2. ì½”ë“œ í¬ë§·íŒ…
```bash
# Blackì„ ì‚¬ìš©í•œ ì½”ë“œ í¬ë§·íŒ…
black DDP_KBIT/

# Flake8ì„ ì‚¬ìš©í•œ ë¦°íŒ…
flake8 DDP_KBIT/
```

### 3. í…ŒìŠ¤íŠ¸ ì‹¤í–‰
```bash
# pytestë¥¼ ì‚¬ìš©í•œ í…ŒìŠ¤íŠ¸
pytest tests/

# ë˜ëŠ” íŠ¹ì • í…ŒìŠ¤íŠ¸ íŒŒì¼
pytest tests/test_training.py
```

## ğŸ†˜ ì§€ì› ë° ë¬¸ì˜

### ë¬¸ì œ í•´ê²° ìˆœì„œ
1. ì´ ê°€ì´ë“œì˜ ë¬¸ì œ í•´ê²° ì„¹ì…˜ í™•ì¸
2. ë¡œê·¸ ë ˆë²¨ì„ DEBUGë¡œ ì„¤ì •í•˜ì—¬ ìƒì„¸ ì •ë³´ í™•ì¸
3. ì„¤ì • íŒŒì¼ ê²€ì¦
4. ì˜ì¡´ì„± ë²„ì „ í˜¸í™˜ì„± í™•ì¸

### ìœ ìš©í•œ ëª…ë ¹ì–´
```bash
# íŒ¨í‚¤ì§€ ì •ë³´ í™•ì¸
pip show ddp-kbit

# ì„¤ì¹˜ëœ íŒ¨í‚¤ì§€ ëª©ë¡
pip list

# Python ê²½ë¡œ í™•ì¸
python -c "import sys; print(sys.path)"

# í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ í™•ì¸
pwd  # Linux/macOS
cd   # Windows
```

### ì¶”ê°€ ë¦¬ì†ŒìŠ¤
- [PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/)
- [Apache Spark ë¬¸ì„œ](https://spark.apache.org/docs/)
- [Apache Kafka ë¬¸ì„œ](https://kafka.apache.org/documentation/)
- [ì›ë³¸ ë…¸íŠ¸ë¶ ì°¸ì¡°](sparkDL_KBIT_gpu_lightning.ipynb)
