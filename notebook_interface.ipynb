{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DDP_KBIT Jupyter Notebook Interface\n",
    "\n",
    "This notebook provides a simple interface to run the DDP_KBIT distributed deep learning system without using command line arguments. It wraps the existing `main.py` functionality for easy experimentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ÏÑ∏ÏÖò Ï¥àÍ∏∞Ìôî (Îß§Î≤à Ïã§Ìñâ ÌïÑÏöî)\n",
    "\n",
    "ÏïÑÎûò ÏÖÄÏùÑ Îß§ ÏÑ∏ÏÖòÎßàÎã§ Í∞ÄÏû• Î®ºÏ†Ä Ïã§ÌñâÌïòÏó¨ Î°úÏª¨ Î™®ÎìàÏóê Ïó∞Í≤∞ÌïòÏÑ∏Ïöî."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.9/site-packages/ignite/handlers/checkpoint.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: config.json not found. Using default values.\n",
      "‚úì Successfully imported DDP_KBIT modules\n",
      "üéâ DDP_KBIT notebook interface ready!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    import ddp_kbit\n",
    "    from ddp_kbit.main import (\n",
    "        setup_logging, \n",
    "        load_external_config,\n",
    "        run_training_mode,\n",
    "        run_experiment_mode, \n",
    "        create_sample_config\n",
    "    )\n",
    "    print(\"‚úì Successfully imported DDP_KBIT modules\")\n",
    "    print(\"üéâ DDP_KBIT notebook interface ready!\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Error importing DDP_KBIT modules: {e}\")\n",
    "    print(\"‚ö†Ô∏è  DDP_KBIT setup incomplete. Some features may not work.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Configuration setup complete\n",
      "Config path: sample_config.json\n",
      "Distributed: False\n",
      "Iterations: 3\n"
     ]
    }
   ],
   "source": [
    "# Setup logging\n",
    "setup_logging(\"INFO\")\n",
    "\n",
    "# Create a mock args object to simulate command line arguments\n",
    "class NotebookArgs:\n",
    "    def __init__(self):\n",
    "        self.config_path = \"sample_config.json\"\n",
    "        self.distributed = False\n",
    "        self.experiment_type = \"single\"\n",
    "        self.iterations = 3\n",
    "        self.log_level = \"INFO\"\n",
    "\n",
    "# Initialize default arguments\n",
    "args = NotebookArgs()\n",
    "\n",
    "print(\"‚úì Configuration setup complete\")\n",
    "print(f\"Config path: {args.config_path}\")\n",
    "print(f\"Distributed: {args.distributed}\")\n",
    "print(f\"Iterations: {args.iterations}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Sample Configuration (Run this first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: config.json not found. Using default values.\n",
      "Created sample_config.json - customize this file for your needs.\n",
      "‚úì Sample configuration created!\n",
      "\n",
      "Current configuration:\n",
      "{\n",
      "  \"training_config\": {\n",
      "    \"base_model_type\": \"NeuralNetwork\",\n",
      "    \"optimizer_class\": \"torch.optim.adam.Adam\",\n",
      "    \"optimizer_params\": {\n",
      "      \"lr\": 0.001\n",
      "    },\n",
      "    \"loss_fn\": \"torch.nn.modules.loss.CrossEntropyLoss\",\n",
      "    \"perform_validation\": true,\n",
      "    \"num_epochs\": 1,\n",
      "    \"batch_size\": 32,\n",
      "    \"metrics\": {\n",
      "      \"loss\": \"Loss\",\n",
      "      \"accuracy\": \"Accuracy\"\n",
      "    }\n",
      "  },\n",
      "  \"mongo_config\": {\n",
      "    \"connection_id\": \"my-mongo-1\",\n",
      "    \"mongo_database\": \"kbit-db\",\n",
      "    \"collection\": \"mnist_train_avro\"\n",
      "  },\n",
      "  \"kafka_config\": {\n",
      "    \"bootstrap_servers\": [\n",
      "      \"155.230.35.200:32100\",\n",
      "      \"155.230.35.213:32100\",\n",
      "      \"155.230.35.215:32100\"\n",
      "    ],\n",
      "    \"data_load_topic\": \"kbit-p3r1\"\n",
      "  },\n",
      "  \"data_loader_config\": {\n",
      "    \"data_loader_type\": \"kafka\",\n",
      "    \"local_data_path\": \"/root/processed_mnist\",\n",
      "    \"offsets_data\": [\n",
      "      \"0:0:19999\",\n",
      "      \"1:0:19999\",\n",
      "      \"2:0:19999\"\n",
      "    ],\n",
      "    \"offsets_data_topic\": \"my-topic-3\",\n",
      "    \"api_config\": {\n",
      "      \"base_url\": \"http://155.230.36.25:3001\",\n",
      "      \"endpoint\": \"data/export\",\n",
      "      \"params\": {\n",
      "        \"connection_id\": \"my-mongo-1\",\n",
      "        \"mongo_database\": \"kbit-db\",\n",
      "        \"collection\": \"mnist_train_avro\",\n",
      "        \"kafka_brokers\": \"155.230.35.200:32100,155.230.35.213:32100,155.230.35.215:32100\",\n",
      "        \"send_topic\": \"kbit-p3r1\"\n",
      "      }\n",
      "    },\n",
      "    \"dataset_split_config\": [\n",
      "      {\n",
      "        \"rate\": 0.85715\n",
      "      },\n",
      "      {\n",
      "        \"rate\": 0.071425\n",
      "      },\n",
      "      {\n",
      "        \"rate\": 0.071425\n",
      "      }\n",
      "    ],\n",
      "    \"consumer_params\": {\n",
      "      \"bootstrap_servers\": [\n",
      "        \"155.230.35.200:32100\",\n",
      "        \"155.230.35.213:32100\",\n",
      "        \"155.230.35.215:32100\"\n",
      "      ]\n",
      "    },\n",
      "    \"payload_config\": {\n",
      "      \"message_format\": \"none\",\n",
      "      \"data_field\": \"data\",\n",
      "      \"label_field\": \"label\",\n",
      "      \"transform_data_fn\": \"transform_mongodb_image\",\n",
      "      \"transform_label_fn\": null\n",
      "    }\n",
      "  },\n",
      "  \"payload_config\": {\n",
      "    \"message_format\": \"none\",\n",
      "    \"data_field\": \"data\",\n",
      "    \"label_field\": \"label\",\n",
      "    \"transform_data_fn\": \"transform_mongodb_image\",\n",
      "    \"transform_label_fn\": null\n",
      "  },\n",
      "  \"metadata\": {\n",
      "    \"generated_from\": \"ddp_kbit.config modules\",\n",
      "    \"description\": \"Sample configuration dynamically generated from existing config modules\",\n",
      "    \"usage_note\": \"This config uses the same settings as defined in the original notebook cell 24\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Create a sample configuration file\n",
    "\n",
    "create_sample_config()\n",
    "print(\"‚úì Sample configuration created!\")\n",
    "\n",
    "# Display the configuration\n",
    "if os.path.exists(\"sample_config.json\"):\n",
    "    with open(\"sample_config.json\", 'r') as f:\n",
    "        config = json.load(f)\n",
    "    print(\"\\nCurrent configuration:\")\n",
    "    print(json.dumps(config, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Mode\n",
    "\n",
    "Run single node or distributed training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-20 13:59:26 - root - INFO - Starting training mode...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting single node training...\n",
      "FILES IN THIS DIRECTORY\n",
      "['DDP_KBIT', 'jars', 'config.json', 'mnist_pb2.py', 'spark_DL_checkpoints', 'sample_config.json']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/08/20 13:59:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/08/20 13:59:28 WARN ResourceUtils: The configuration of cores (exec = 5 task = 1, runnable tasks = 5) will result in wasted resources due to resource gpu limiting the number of runnable tasks per executor to: 1. Please adjust your configuration.\n",
      "25/08/20 13:59:29 WARN RapidsPluginUtils: RAPIDS Accelerator 24.06.1 using cudf 24.06.0, private revision 755b4dd03c753cacb7d141f3b3c8ff9f83888b69\n",
      "25/08/20 13:59:29 WARN RapidsPluginUtils: spark.rapids.sql.multiThreadedRead.numThreads is set to 20.\n",
      "25/08/20 13:59:29 WARN RapidsPluginUtils: The current setting of spark.task.resource.gpu.amount (1.0) is not ideal to get the best performance from the RAPIDS Accelerator plugin. It's recommended to be 1/{executor core count} unless you have a special use case.\n",
      "25/08/20 13:59:29 WARN RapidsPluginUtils: RAPIDS Accelerator is enabled, to disable GPU support set `spark.rapids.sql.enabled` to false.\n",
      "25/08/20 13:59:29 WARN RapidsPluginUtils: spark.rapids.sql.explain is set to `NOT_ON_GPU`. Set it to 'NONE' to suppress the diagnostics logging about the query placement on the GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Spark configuration:\n",
      "spark.app.id = app-20250820135929-0057\n",
      "spark.app.initial.file.urls = spark://192.168.141.56:39337/files/mnist_pb2.py\n",
      "spark.app.initial.jar.urls = spark://192.168.141.56:39337/jars/jsr305-3.0.0.jar,spark://192.168.141.56:39337/jars/spark-sql-kafka-0-10_2.12-3.5.1.jar,spark://192.168.141.56:39337/jars/commons-pool2-2.11.1.jar,spark://192.168.141.56:39337/jars/rapids-4-spark_2.12-24.06.1.jar,spark://192.168.141.56:39337/jars/commons-logging-1.1.3.jar,spark://192.168.141.56:39337/jars/spark-token-provider-kafka-0-10_2.12-3.5.1.jar,spark://192.168.141.56:39337/jars/hadoop-client-runtime-3.3.4.jar,spark://192.168.141.56:39337/jars/lz4-java-1.8.0.jar,spark://192.168.141.56:39337/jars/kafka-clients-3.4.1.jar,spark://192.168.141.56:39337/jars/spark-streaming-kafka-0-10_2.12-3.5.1.jar,spark://192.168.141.56:39337/jars/slf4j-api-2.0.7.jar,spark://192.168.141.56:39337/jars/snappy-java-1.1.10.3.jar,spark://192.168.141.56:39337/jars/hadoop-client-api-3.3.4.jar\n",
      "spark.app.name = DDP_KBIT_Training\n",
      "spark.app.startTime = 1755698368330\n",
      "spark.app.submitTime = 1755698368149\n",
      "spark.defaul.parallelism = 30\n",
      "spark.default.parallelism = 64\n",
      "spark.driver.extraJavaOptions = -Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false\n",
      "spark.driver.host = 192.168.141.56\n",
      "spark.driver.port = 39337\n",
      "spark.executor.cores = 5\n",
      "spark.executor.extraJavaOptions = -Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false\n",
      "spark.executor.id = driver\n",
      "spark.executor.instances = 3\n",
      "spark.executor.memory = 24g\n",
      "spark.executor.resource.gpu.amount = 1\n",
      "spark.executor.resource.gpu.discoveryScript = /opt/spark/conf/getGpusResources.sh\n",
      "spark.files = file:///mnt/data/mnist_pb2.py\n",
      "spark.jars = jars/commons-logging-1.1.3.jar,jars/commons-pool2-2.11.1.jar,jars/hadoop-client-api-3.3.4.jar,jars/hadoop-client-runtime-3.3.4.jar,jars/jsr305-3.0.0.jar,jars/kafka-clients-3.4.1.jar,jars/lz4-java-1.8.0.jar,jars/slf4j-api-2.0.7.jar,jars/snappy-java-1.1.10.3.jar,jars/spark-sql-kafka-0-10_2.12-3.5.1.jar,jars/spark-streaming-kafka-0-10_2.12-3.5.1.jar,jars/spark-token-provider-kafka-0-10_2.12-3.5.1.jar,jars/rapids-4-spark_2.12-24.06.1.jar\n",
      "spark.master = spark://spark-master-service:7077\n",
      "spark.plugins = com.nvidia.spark.SQLPlugin\n",
      "spark.plugins.internal.conf.com.nvidia.spark.SQLPlugin.spark.rapids.driver.user.timezone = Z\n",
      "spark.plugins.internal.conf.com.nvidia.spark.SQLPlugin.spark.rapids.memory.gpu.minAllocFraction = 0.1\n",
      "spark.plugins.internal.conf.com.nvidia.spark.SQLPlugin.spark.rapids.memory.pinnedPool.size = 2g\n",
      "spark.plugins.internal.conf.com.nvidia.spark.SQLPlugin.spark.rapids.sql.concurrentGpuTasks = 1\n",
      "spark.plugins.internal.conf.com.nvidia.spark.SQLPlugin.spark.rapids.sql.multiThreadedRead.numThreads = 20\n",
      "spark.rapids.driver.user.timezone = Z\n",
      "spark.rapids.memory.gpu.minAllocFraction = 0.1\n",
      "spark.rapids.memory.pinnedPool.size = 2g\n",
      "spark.rapids.sql.concurrentGpuTasks = 1\n",
      "spark.rapids.sql.multiThreadedRead.numThreads = 20\n",
      "spark.rdd.compress = True\n",
      "spark.repl.local.jars = file:///mnt/data/jars/commons-logging-1.1.3.jar,file:///mnt/data/jars/commons-pool2-2.11.1.jar,file:///mnt/data/jars/hadoop-client-api-3.3.4.jar,file:///mnt/data/jars/hadoop-client-runtime-3.3.4.jar,file:///mnt/data/jars/jsr305-3.0.0.jar,file:///mnt/data/jars/kafka-clients-3.4.1.jar,file:///mnt/data/jars/lz4-java-1.8.0.jar,file:///mnt/data/jars/slf4j-api-2.0.7.jar,file:///mnt/data/jars/snappy-java-1.1.10.3.jar,file:///mnt/data/jars/spark-sql-kafka-0-10_2.12-3.5.1.jar,file:///mnt/data/jars/spark-streaming-kafka-0-10_2.12-3.5.1.jar,file:///mnt/data/jars/spark-token-provider-kafka-0-10_2.12-3.5.1.jar,file:///mnt/data/jars/rapids-4-spark_2.12-24.06.1.jar\n",
      "spark.serializer.objectStreamReset = 100\n",
      "spark.sql.extensions = com.nvidia.spark.rapids.SQLExecPlugin,com.nvidia.spark.udf.Plugin,com.nvidia.spark.rapids.optimizer.SQLOptimizerPlugin\n",
      "spark.sql.shuffle.partitions = 30\n",
      "spark.submit.deployMode = client\n",
      "spark.submit.pyFiles = mnist_pb2.py\n",
      "spark.task.resource.gpu.amount = 1\n",
      "spark.ui.showConsoleProgress = true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-20 13:59:31 - TorchDistributor - INFO - Started distributed training with 3 executor processes\n",
      "2025-08-20 13:59:33 - numexpr.utils - INFO - Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2025-08-20 13:59:33 - numexpr.utils - INFO - NumExpr defaulting to 8 threads.\n",
      "/usr/local/lib/python3.9/dist-packages/ignite/handlers/checkpoint.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
      "/usr/local/lib/python3.9/dist-packages/ignite/handlers/checkpoint.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
      "/usr/local/lib/python3.9/dist-packages/ignite/handlers/checkpoint.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
      "Warning: config.json not found. Using default values.\n",
      "Warning: config.json not found. Using default values.\n",
      "Warning: config.json not found. Using default values.\n",
      "/usr/local/lib/python3.9/dist-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "Starting distributed training initialization...\n",
      "/usr/local/lib/python3.9/dist-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "Starting distributed training initialization...\n",
      "/usr/local/lib/python3.9/dist-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "Starting distributed training initialization...\n",
      "idist.get_rank()=2\n",
      "idist.backend()='nccl'\n",
      "idist.get_world_size()=3\n",
      "device=device(type='cuda', index=0) & type(device)=<class 'torch.device'>\n",
      "[PID 8790] Initializing process group with: {'MASTER_ADDR': '192.168.109.174', 'MASTER_PORT': '51451', 'RANK': '2', 'WORLD_SIZE': '3', 'LOCAL_RANK': '0'}\n",
      "[PID 8790] world_size = 3, global_rank = 2, local_rank = 0, backend = nccl, device_ids = [0]\n",
      "Training metrics tracking started\n",
      "RANK[2] DataLoader Config: {'data_loader_type': 'kafka', 'local_data_path': '/root/processed_mnist', 'offsets_data': ['0:0:19999', '1:0:19999', '2:0:19999'], 'offsets_data_topic': 'my-topic-3', 'api_config': {'base_url': 'http://155.230.36.25:3001', 'endpoint': 'data/export', 'params': {'connection_id': 'my-mongo-1', 'mongo_database': 'kbit-db', 'collection': 'mnist_train_avro', 'kafka_brokers': '155.230.35.200:32100,155.230.35.213:32100,155.230.35.215:32100', 'send_topic': 'kbit-p3r1'}}, 'dataset_split_config': [{'rate': 0.85715}, {'rate': 0.071425}, {'rate': 0.071425}], 'consumer_params': {'bootstrap_servers': ['155.230.35.200:32100', '155.230.35.213:32100', '155.230.35.215:32100']}, 'payload_config': {'message_format': 'none', 'data_field': 'data', 'label_field': 'label', 'transform_data_fn': <function transform_mongodb_image at 0x7f1eb498baf0>, 'transform_label_fn': None}}\n",
      "idist.get_rank()=1\n",
      "idist.backend()='nccl'\n",
      "idist.get_world_size()=3\n",
      "device=device(type='cuda', index=0) & type(device)=<class 'torch.device'>\n",
      "[PID 9060] Initializing process group with: {'MASTER_ADDR': '192.168.109.174', 'MASTER_PORT': '51451', 'RANK': '1', 'WORLD_SIZE': '3', 'LOCAL_RANK': '0'}\n",
      "[PID 9060] world_size = 3, global_rank = 1, local_rank = 0, backend = nccl, device_ids = [0]\n",
      "Training metrics tracking started\n",
      "RANK[1] DataLoader Config: {'data_loader_type': 'kafka', 'local_data_path': '/root/processed_mnist', 'offsets_data': ['0:0:19999', '1:0:19999', '2:0:19999'], 'offsets_data_topic': 'my-topic-3', 'api_config': {'base_url': 'http://155.230.36.25:3001', 'endpoint': 'data/export', 'params': {'connection_id': 'my-mongo-1', 'mongo_database': 'kbit-db', 'collection': 'mnist_train_avro', 'kafka_brokers': '155.230.35.200:32100,155.230.35.213:32100,155.230.35.215:32100', 'send_topic': 'kbit-p3r1'}}, 'dataset_split_config': [{'rate': 0.85715}, {'rate': 0.071425}, {'rate': 0.071425}], 'consumer_params': {'bootstrap_servers': ['155.230.35.200:32100', '155.230.35.213:32100', '155.230.35.215:32100']}, 'payload_config': {'message_format': 'none', 'data_field': 'data', 'label_field': 'label', 'transform_data_fn': <function transform_mongodb_image at 0x7f6386e928b0>, 'transform_label_fn': None}}\n",
      "idist.get_rank()=0\n",
      "idist.backend()='nccl'\n",
      "idist.get_world_size()=3\n",
      "device=device(type='cuda', index=0) & type(device)=<class 'torch.device'>\n",
      "[PID 8597] Initializing process group with: {'MASTER_ADDR': '192.168.109.174', 'MASTER_PORT': '51451', 'RANK': '0', 'WORLD_SIZE': '3', 'LOCAL_RANK': '0'}\n",
      "[PID 8597] world_size = 3, global_rank = 0, local_rank = 0, backend = nccl, device_ids = [0]\n",
      "Training metrics tracking started\n",
      "RANK[0] DataLoader Config: {'data_loader_type': 'kafka', 'local_data_path': '/root/processed_mnist', 'offsets_data': ['0:0:19999', '1:0:19999', '2:0:19999'], 'offsets_data_topic': 'my-topic-3', 'api_config': {'base_url': 'http://155.230.36.25:3001', 'endpoint': 'data/export', 'params': {'connection_id': 'my-mongo-1', 'mongo_database': 'kbit-db', 'collection': 'mnist_train_avro', 'kafka_brokers': '155.230.35.200:32100,155.230.35.213:32100,155.230.35.215:32100', 'send_topic': 'kbit-p3r1'}}, 'dataset_split_config': [{'rate': 0.85715}, {'rate': 0.071425}, {'rate': 0.071425}], 'consumer_params': {'bootstrap_servers': ['155.230.35.200:32100', '155.230.35.213:32100', '155.230.35.215:32100']}, 'payload_config': {'message_format': 'none', 'data_field': 'data', 'label_field': 'label', 'transform_data_fn': <function transform_mongodb_image at 0x7f58a2924af0>, 'transform_label_fn': None}}\n",
      "Rank 2 Polling:   0%|          | 0/17142 [00:00<?, ?msg/s]Rank 2 : Î©îÏÑ∏ÏßÄ Polling Start 0 ~ 17141\n",
      "Rank 1 Polling:   0%|          | 0/17142 [00:00<?, ?msg/s]Rank 1 : Î©îÏÑ∏ÏßÄ Polling Start 0 ~ 17141\n",
      "Topic 'kbit-p3r1' has 3 partitions. WORLD_SIZE is 3.\n",
      "The number of partitions matches the WORLD_SIZE.\n",
      "Rank 2 Polling:   0%|          | 1/17142 [00:00<1:27:35,  3.26msg/s]\n",
      "Rank 1 Polling:   0%|          | 1/17142 [00:00<1:27:39,  3.26msg/s]\n",
      "Rank 0 Polling:   0%|          | 0/17142 [00:00<?, ?msg/s]Rank 0 : Î©îÏÑ∏ÏßÄ Polling Start 0 ~ 17141\n",
      "Rank 2 Polling:   0%|          | 0/1429 [00:00<?, ?msg/s]Rank 2 : Î©îÏÑ∏ÏßÄ Polling Start 17142 ~ 18570\n",
      "Rank 1 Polling:   0%|          | 0/1429 [00:00<?, ?msg/s]Rank 1 : Î©îÏÑ∏ÏßÄ Polling Start 17142 ~ 18570\n",
      "Rank 2 Polling:   0%|          | 1/1429 [00:00<03:03,  7.80msg/s]\n",
      "Rank 0 Polling:   0%|          | 1/17142 [00:00<1:01:06,  4.68msg/s]\n",
      "Rank 0 Polling:   0%|          | 0/1429 [00:00<?, ?msg/s]Rank 0 : Î©îÏÑ∏ÏßÄ Polling Start 17142 ~ 18570\n",
      "Rank 2 Polling:   0%|          | 0/1429 [00:00<?, ?msg/s]Rank 2 : Î©îÏÑ∏ÏßÄ Polling Start 18571 ~ 19999\n",
      "Rank 1 Polling:   0%|          | 1/1429 [00:00<07:26,  3.20msg/s]\n",
      "Rank 2 Polling:   0%|          | 1/1429 [00:00<04:22,  5.44msg/s]\n",
      "Rank 2: Data size after sampling: 1429\n",
      "Rank 2: Creating DataLoader with batch size 10\n",
      "Finished Data Loading. Total time: 0.94 seconds\n",
      "RANK[2] Train Loader Debug:\n",
      "RANK[2] Validation Loader Debug:\n",
      "RANK[2] Test Loader Debug:\n",
      "Rank 1 Polling:   0%|          | 0/1429 [00:00<?, ?msg/s]Rank 1 : Î©îÏÑ∏ÏßÄ Polling Start 18571 ~ 19999\n",
      "Rank 0 Polling:   0%|          | 1/1429 [00:00<05:08,  4.63msg/s]\n",
      "Rank 0 Polling:   0%|          | 0/1429 [00:00<?, ?msg/s]Rank 0 : Î©îÏÑ∏ÏßÄ Polling Start 18571 ~ 19999\n",
      "Rank 1 Polling:   0%|          | 1/1429 [00:00<04:39,  5.12msg/s]\n",
      "Rank 1: Data size after sampling: 1429\n",
      "Rank 1: Creating DataLoader with batch size 10\n",
      "Finished Data Loading. Total time: 1.14 seconds\n",
      "RANK[1] Train Loader Debug:\n",
      "RANK[1] Validation Loader Debug:\n",
      "RANK[1] Test Loader Debug:\n",
      "Rank 0 Polling:   0%|          | 1/1429 [00:00<05:08,  4.63msg/s]\n",
      "Rank 0: Data size after sampling: 1429\n",
      "Rank 0: Creating DataLoader with batch size 10\n",
      "Finished Data Loading. Total time: 1.31 seconds\n",
      "RANK[0] Train Loader Debug:\n",
      "    Total number of samples in the dataset: 1\n",
      "    Batch index: 0\n",
      "    Data shape: torch.Size([1, 1, 28, 28])\n",
      "    Data type: torch.float32\n",
      "    Target shape: torch.Size([1])\n",
      "    Target type: torch.int64\n",
      "    Data range: [0.0000, 1.0000]\n",
      "    Unique targets in batch: [5]\n",
      "RANK[0] Validation Loader Debug:\n",
      "    Total number of samples in the dataset: 1\n",
      "    Batch index: 0\n",
      "    Data shape: torch.Size([1, 1, 28, 28])\n",
      "    Data type: torch.float32\n",
      "    Target shape: torch.Size([1])\n",
      "    Target type: torch.int64\n",
      "    Data range: [0.0000, 1.0000]\n",
      "    Unique targets in batch: [5]\n",
      "RANK[0] Test Loader Debug:\n",
      "    Total number of samples in the dataset: 1429\n",
      "    Batch index: 0\n",
      "    Data shape: torch.Size([10, 1, 28, 28])\n",
      "    Data type: torch.float32\n",
      "    Target shape: torch.Size([10])\n",
      "    Target type: torch.int64\n",
      "    Data range: [0.0000, 1.0000]\n",
      "    Unique targets in batch: [5]\n",
      "2025-08-20 13:59:59,833 ignite.distributed.auto.auto_model INFO: Apply torch DistributedDataParallel on model, device id: 0\n",
      "type(model)=<class 'torch.nn.parallel.distributed.DistributedDataParallel'>, model=DistributedDataParallel(\n",
      "  (module): NeuralNetwork(\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "    (linear_relu_stack): Sequential(\n",
      "      (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "type(optimizer)=<class 'torch.optim.adam.Adam'>, optimizer=Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "type(training_config['loss_fn'])=<class 'torch.nn.modules.loss.CrossEntropyLoss'>, training_config['loss_fn']=CrossEntropyLoss()\n",
      "\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "Starting Epoch 1/1\n",
      "\n",
      "Train Epoch: 1\n",
      "train_metrics loss = 2.2668086687723794\n",
      "train_metrics accuracy = 0.3333333333333333\n",
      "val_metrics loss = 1.9150511423746746\n",
      "val_metrics accuracy = 1.0\n",
      "_ _ _ _ Finished training. Total training time: 0.20 seconds _ _ _ _\n",
      "\n",
      "Test Results:\n",
      "test_metrics loss = 1.915050452312223\n",
      "test_metrics accuracy = 1.0\n",
      "_ _ _ _ Finished testing. Total testing time: 0.11 seconds _ _ _ _\n",
      "\n",
      "==================================================\n",
      "TRAINING METRICS SUMMARY\n",
      "==================================================\n",
      "Total training time: 1.99 seconds\n",
      "Average epoch time: 0.20 seconds\n",
      "Total epochs completed: 1\n",
      "\n",
      "TRAIN METRICS:\n",
      "  loss:\n",
      "    Latest: 2.2668\n",
      "    Best: 2.2668 (Epoch 1)\n",
      "  accuracy:\n",
      "    Latest: 0.3333\n",
      "    Best: 0.3333 (Epoch 1)\n",
      "\n",
      "VAL METRICS:\n",
      "  loss:\n",
      "    Latest: 1.9151\n",
      "    Best: 1.9151 (Epoch 1)\n",
      "  accuracy:\n",
      "    Latest: 1.0000\n",
      "    Best: 1.0000 (Epoch 1)\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "PERFORMANCE PROFILE\n",
      "==================================================\n",
      "kafka_data_fetch:\n",
      "  Count: 1\n",
      "  Total time: 1.3125s\n",
      "  Average time: 1.3125s\n",
      "  Min time: 1.3125s\n",
      "  Max time: 1.3125s\n",
      "\n",
      "data_loading:\n",
      "  Count: 1\n",
      "  Total time: 1.3129s\n",
      "  Average time: 1.3129s\n",
      "  Min time: 1.3129s\n",
      "  Max time: 1.3129s\n",
      "\n",
      "training:\n",
      "  Count: 1\n",
      "  Total time: 0.2015s\n",
      "  Average time: 0.2015s\n",
      "  Min time: 0.2015s\n",
      "  Max time: 0.2015s\n",
      "\n",
      "testing:\n",
      "  Count: 1\n",
      "  Total time: 0.1095s\n",
      "  Average time: 0.1095s\n",
      "  Min time: 0.1095s\n",
      "  Max time: 0.1095s\n",
      "\n",
      "Distributed process group destroyed successfully\n",
      "Distributed process group destroyed successfully\n",
      "Distributed process group destroyed successfully\n",
      "2025-08-20 14:00:02 - TorchDistributor - INFO - Finished distributed training with 3 executor processes\n",
      "2025-08-20 14:00:02 - root - INFO - Training completed successfully!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Training completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Single node training\n",
    "print(\"üöÄ Starting single node training...\")\n",
    "args.distributed = False\n",
    "\n",
    "try:\n",
    "    run_training_mode(args)\n",
    "    print(\"‚úÖ Training completed successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Training failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distributed training (uncomment to run)\n",
    "# print(\"üöÄ Starting distributed training...\")\n",
    "# args.distributed = True\n",
    "\n",
    "# try:\n",
    "#     run_training_mode(args)\n",
    "#     print(\"‚úÖ Distributed training completed successfully!\")\n",
    "# except Exception as e:\n",
    "#     print(f\"‚ùå Distributed training failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Mode\n",
    "\n",
    "Run single experiments or multiple iterations with statistical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-20 14:00:02 - root - INFO - Starting experiment mode: single\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Running single experiment...\n",
      "FILES IN THIS DIRECTORY\n",
      "['DDP_KBIT', 'jars', 'config.json', 'mnist_pb2.py', 'spark_DL_checkpoints', 'sample_config.json']\n",
      "Current Spark configuration:\n",
      "spark.app.id = app-20250820140003-0058\n",
      "spark.app.initial.file.urls = spark://192.168.141.56:39337/files/mnist_pb2.py\n",
      "spark.app.initial.jar.urls = spark://192.168.141.56:39337/jars/jsr305-3.0.0.jar,spark://192.168.141.56:39337/jars/spark-sql-kafka-0-10_2.12-3.5.1.jar,spark://192.168.141.56:39337/jars/commons-pool2-2.11.1.jar,spark://192.168.141.56:39337/jars/rapids-4-spark_2.12-24.06.1.jar,spark://192.168.141.56:39337/jars/commons-logging-1.1.3.jar,spark://192.168.141.56:39337/jars/spark-token-provider-kafka-0-10_2.12-3.5.1.jar,spark://192.168.141.56:39337/jars/hadoop-client-runtime-3.3.4.jar,spark://192.168.141.56:39337/jars/lz4-java-1.8.0.jar,spark://192.168.141.56:39337/jars/kafka-clients-3.4.1.jar,spark://192.168.141.56:39337/jars/spark-streaming-kafka-0-10_2.12-3.5.1.jar,spark://192.168.141.56:39337/jars/slf4j-api-2.0.7.jar,spark://192.168.141.56:39337/jars/snappy-java-1.1.10.3.jar,spark://192.168.141.56:39337/jars/hadoop-client-api-3.3.4.jar\n",
      "spark.app.name = DDP_KBIT_Experiments\n",
      "spark.app.startTime = 1755698402981\n",
      "spark.app.submitTime = 1755698368149\n",
      "spark.defaul.parallelism = 30\n",
      "spark.default.parallelism = 64\n",
      "spark.driver.extraJavaOptions = -Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false\n",
      "spark.driver.host = 192.168.141.56\n",
      "spark.driver.port = 39337\n",
      "spark.executor.cores = 5\n",
      "spark.executor.extraJavaOptions = -Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false\n",
      "spark.executor.id = driver\n",
      "spark.executor.instances = 3\n",
      "spark.executor.memory = 24g\n",
      "spark.executor.resource.gpu.amount = 1\n",
      "spark.executor.resource.gpu.discoveryScript = /opt/spark/conf/getGpusResources.sh\n",
      "spark.files = file:///mnt/data/mnist_pb2.py\n",
      "spark.jars = jars/commons-logging-1.1.3.jar,jars/commons-pool2-2.11.1.jar,jars/hadoop-client-api-3.3.4.jar,jars/hadoop-client-runtime-3.3.4.jar,jars/jsr305-3.0.0.jar,jars/kafka-clients-3.4.1.jar,jars/lz4-java-1.8.0.jar,jars/slf4j-api-2.0.7.jar,jars/snappy-java-1.1.10.3.jar,jars/spark-sql-kafka-0-10_2.12-3.5.1.jar,jars/spark-streaming-kafka-0-10_2.12-3.5.1.jar,jars/spark-token-provider-kafka-0-10_2.12-3.5.1.jar,jars/rapids-4-spark_2.12-24.06.1.jar\n",
      "spark.master = spark://spark-master-service:7077\n",
      "spark.plugins = com.nvidia.spark.SQLPlugin\n",
      "spark.plugins.internal.conf.com.nvidia.spark.SQLPlugin.spark.rapids.driver.user.timezone = Z\n",
      "spark.plugins.internal.conf.com.nvidia.spark.SQLPlugin.spark.rapids.memory.gpu.minAllocFraction = 0.1\n",
      "spark.plugins.internal.conf.com.nvidia.spark.SQLPlugin.spark.rapids.memory.pinnedPool.size = 2g\n",
      "spark.plugins.internal.conf.com.nvidia.spark.SQLPlugin.spark.rapids.sql.concurrentGpuTasks = 1\n",
      "spark.plugins.internal.conf.com.nvidia.spark.SQLPlugin.spark.rapids.sql.multiThreadedRead.numThreads = 20\n",
      "spark.rapids.driver.user.timezone = Z\n",
      "spark.rapids.memory.gpu.minAllocFraction = 0.1\n",
      "spark.rapids.memory.pinnedPool.size = 2g\n",
      "spark.rapids.sql.concurrentGpuTasks = 1\n",
      "spark.rapids.sql.multiThreadedRead.numThreads = 20\n",
      "spark.rdd.compress = True\n",
      "spark.repl.local.jars = file:///mnt/data/jars/commons-logging-1.1.3.jar,file:///mnt/data/jars/commons-pool2-2.11.1.jar,file:///mnt/data/jars/hadoop-client-api-3.3.4.jar,file:///mnt/data/jars/hadoop-client-runtime-3.3.4.jar,file:///mnt/data/jars/jsr305-3.0.0.jar,file:///mnt/data/jars/kafka-clients-3.4.1.jar,file:///mnt/data/jars/lz4-java-1.8.0.jar,file:///mnt/data/jars/slf4j-api-2.0.7.jar,file:///mnt/data/jars/snappy-java-1.1.10.3.jar,file:///mnt/data/jars/spark-sql-kafka-0-10_2.12-3.5.1.jar,file:///mnt/data/jars/spark-streaming-kafka-0-10_2.12-3.5.1.jar,file:///mnt/data/jars/spark-token-provider-kafka-0-10_2.12-3.5.1.jar,file:///mnt/data/jars/rapids-4-spark_2.12-24.06.1.jar\n",
      "spark.serializer.objectStreamReset = 100\n",
      "spark.sql.extensions = com.nvidia.spark.rapids.SQLExecPlugin,com.nvidia.spark.udf.Plugin,com.nvidia.spark.rapids.optimizer.SQLOptimizerPlugin\n",
      "spark.sql.shuffle.partitions = 30\n",
      "spark.submit.deployMode = client\n",
      "spark.submit.pyFiles = mnist_pb2.py\n",
      "spark.task.resource.gpu.amount = 1\n",
      "spark.ui.showConsoleProgress = true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-20 14:00:04 - TorchDistributor - INFO - Started distributed training with 3 executor processes\n",
      "/usr/local/lib/python3.9/dist-packages/ignite/handlers/checkpoint.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
      "/usr/local/lib/python3.9/dist-packages/ignite/handlers/checkpoint.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
      "Warning: config.json not found. Using default values.\n",
      "Warning: config.json not found. Using default values.\n",
      "/usr/local/lib/python3.9/dist-packages/ignite/handlers/checkpoint.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
      "Warning: config.json not found. Using default values.\n",
      "/usr/local/lib/python3.9/dist-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "Running data loading experiment with 4 configurations\n",
      "/usr/local/lib/python3.9/dist-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "Running data loading experiment with 4 configurations\n",
      "/usr/local/lib/python3.9/dist-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "Running data loading experiment with 4 configurations\n",
      "[PID 9189] world_size = 3, global_rank = 2, local_rank = 0\n",
      "RANK[2] Ïã§Ìóò: avro_lz4, ÌÜ†ÌîΩ: my-topic-4\n",
      "Rank 2: API URL = http://155.230.36.25:3001/data/export/?connection_id=my-mongo-1&mongo_database=kbit-db&collection=mnist_train_avro&kafka_brokers=155.230.35.200%3A32100%2C155.230.35.213%3A32100%2C155.230.35.215%3A32100&send_topic=kbit-p3r1\n",
      "[PID 8917] world_size = 3, global_rank = 1, local_rank = 0\n",
      "RANK[1] Ïã§Ìóò: avro_lz4, ÌÜ†ÌîΩ: my-topic-4\n",
      "Rank 1: API URL = http://155.230.36.25:3001/data/export/?connection_id=my-mongo-1&mongo_database=kbit-db&collection=mnist_train_avro&kafka_brokers=155.230.35.200%3A32100%2C155.230.35.213%3A32100%2C155.230.35.215%3A32100&send_topic=kbit-p3r1\n",
      "[PID 8729] world_size = 3, global_rank = 0, local_rank = 0\n",
      "\n",
      "===== avro_lz4 Ïã§Ìóò ÏãúÏûë =====\n",
      "RANK[0] Ïã§Ìóò: avro_lz4, ÌÜ†ÌîΩ: my-topic-4\n",
      "Rank 0: API URL = http://155.230.36.25:3001/data/export/?connection_id=my-mongo-1&mongo_database=kbit-db&collection=mnist_train_avro&kafka_brokers=155.230.35.200%3A32100%2C155.230.35.213%3A32100%2C155.230.35.215%3A32100&send_topic=kbit-p3r1\n",
      "Rank 2 Polling:   0%|          | 0/17142 [00:00<?, ?msg/s]Rank 2 : Î©îÏÑ∏ÏßÄ Polling Start 0 ~ 17141\n",
      "Rank 1 Polling:   0%|          | 0/17142 [00:00<?, ?msg/s]Rank 1 : Î©îÏÑ∏ÏßÄ Polling Start 0 ~ 17141\n",
      "Rank 1 Polling:   0%|          | 1/17142 [00:00<12:09, 23.49msg/s]\n",
      "Rank 0 Polling:   0%|          | 0/17142 [00:00<?, ?msg/s]Rank 0 : Î©îÏÑ∏ÏßÄ Polling Start 0 ~ 17141\n",
      "Rank 2 Polling:   0%|          | 1/17142 [00:00<08:19, 34.33msg/s]\n",
      "Rank 1 Polling:   0%|          | 0/1429 [00:00<?, ?msg/s]Rank 1 : Î©îÏÑ∏ÏßÄ Polling Start 17142 ~ 18570\n",
      "Rank 2 Polling:   0%|          | 0/1429 [00:00<?, ?msg/s]Rank 2 : Î©îÏÑ∏ÏßÄ Polling Start 17142 ~ 18570\n",
      "Rank 0 Polling:   0%|          | 1/17142 [00:00<1:05:52,  4.34msg/s]\n",
      "Rank 1 Polling:   0%|          | 1/1429 [00:00<05:02,  4.72msg/s]\n",
      "Rank 0 Polling:   0%|          | 0/1429 [00:00<?, ?msg/s]Rank 0 : Î©îÏÑ∏ÏßÄ Polling Start 17142 ~ 18570\n",
      "Rank 2 Polling:   0%|          | 1/1429 [00:00<04:31,  5.26msg/s]\n",
      "Rank 1 Polling:   0%|          | 0/1429 [00:00<?, ?msg/s]Rank 1 : Î©îÏÑ∏ÏßÄ Polling Start 18571 ~ 19999\n",
      "Rank 2 Polling:   0%|          | 0/1429 [00:00<?, ?msg/s]Rank 2 : Î©îÏÑ∏ÏßÄ Polling Start 18571 ~ 19999\n",
      "Rank 2 Polling:   0%|          | 1/1429 [00:00<00:38, 36.80msg/s]\n",
      "Rank 2: Data size after sampling: 1429\n",
      "Rank 2: Creating DataLoader with batch size 10\n",
      "Rank 1 Polling:   0%|          | 1/1429 [00:00<04:19,  5.50msg/s]\n",
      "Rank 1: Data size after sampling: 1429\n",
      "Rank 1: Creating DataLoader with batch size 10\n",
      "Rank 0 Polling:   0%|          | 1/1429 [00:00<05:23,  4.41msg/s]\n",
      "Rank 0 Polling:   0%|          | 0/1429 [00:00<?, ?msg/s]Rank 0 : Î©îÏÑ∏ÏßÄ Polling Start 18571 ~ 19999\n",
      "Rank 0 Polling:   0%|          | 1/1429 [00:00<04:36,  5.16msg/s]\n",
      "Rank 0: Data size after sampling: 1429\n",
      "Rank 0: Creating DataLoader with batch size 10\n",
      "Î™®Îì† RankÏùò Îç∞Ïù¥ÌÑ∞ Î°úÎî© ÏãúÍ∞Ñ: ['0.987Ï¥à', '0.750Ï¥à', '0.566Ï¥à']\n",
      "Í∞Å RankÎ≥Ñ Î∞∞Ïπò Ï†ïÎ≥¥:\n",
      "Rank 0: Train=1, Val=1, Test=143\n",
      "Rank 1: Train=1, Val=1, Test=143\n",
      "Rank 2: Train=1, Val=1, Test=143\n",
      "avro_lz4 - ÌèâÍ∑†: 0.77Ï¥à, ÏµúÏÜå: 0.57Ï¥à, ÏµúÎåÄ: 0.99Ï¥à\n",
      "RANK[1] Ïã§Ìóò: avro_none, ÌÜ†ÌîΩ: my-topic-5\n",
      "Rank 1: API URL = http://155.230.36.25:3001/data/export/?connection_id=my-mongo-1&mongo_database=kbit-db&collection=mnist_train_avro&kafka_brokers=155.230.35.200%3A32100%2C155.230.35.213%3A32100%2C155.230.35.215%3A32100&send_topic=kbit-p3r1\n",
      "\n",
      "===== avro_none Ïã§Ìóò ÏãúÏûë =====\n",
      "RANK[0] Ïã§Ìóò: avro_none, ÌÜ†ÌîΩ: my-topic-5\n",
      "Rank 0: API URL = http://155.230.36.25:3001/data/export/?connection_id=my-mongo-1&mongo_database=kbit-db&collection=mnist_train_avro&kafka_brokers=155.230.35.200%3A32100%2C155.230.35.213%3A32100%2C155.230.35.215%3A32100&send_topic=kbit-p3r1\n",
      "RANK[2] Ïã§Ìóò: avro_none, ÌÜ†ÌîΩ: my-topic-5\n",
      "Rank 2: API URL = http://155.230.36.25:3001/data/export/?connection_id=my-mongo-1&mongo_database=kbit-db&collection=mnist_train_avro&kafka_brokers=155.230.35.200%3A32100%2C155.230.35.213%3A32100%2C155.230.35.215%3A32100&send_topic=kbit-p3r1\n",
      "Rank 1 Polling:   0%|          | 0/17142 [00:00<?, ?msg/s]Rank 1 : Î©îÏÑ∏ÏßÄ Polling Start 0 ~ 17141\n",
      "Rank 0 Polling:   0%|          | 0/17142 [00:00<?, ?msg/s]Rank 0 : Î©îÏÑ∏ÏßÄ Polling Start 0 ~ 17141\n",
      "Rank 2 Polling:   0%|          | 0/17142 [00:00<?, ?msg/s]Rank 2 : Î©îÏÑ∏ÏßÄ Polling Start 0 ~ 17141\n",
      "Rank 1 : 0 ~ 17141 polling Timeout... try again\n",
      "Rank 1 Polling:   0%|          | 0/17142 [00:03<?, ?msg/s]\n",
      "Rank 0 : 0 ~ 17141 polling Timeout... try again\n",
      "Rank 0 Polling:   0%|          | 0/17142 [00:03<?, ?msg/s]\n",
      "Rank 2 : 0 ~ 17141 polling Timeout... try again\n",
      "Rank 2 Polling:   0%|          | 0/17142 [00:03<?, ?msg/s]\n",
      "Rank 1 Polling:   0%|          | 0/1429 [00:00<?, ?msg/s]Rank 1 : Î©îÏÑ∏ÏßÄ Polling Start 17142 ~ 18570\n",
      "Rank 0 Polling:   0%|          | 0/1429 [00:00<?, ?msg/s]Rank 0 : Î©îÏÑ∏ÏßÄ Polling Start 17142 ~ 18570\n",
      "Rank 2 Polling:   0%|          | 0/1429 [00:00<?, ?msg/s]Rank 2 : Î©îÏÑ∏ÏßÄ Polling Start 17142 ~ 18570\n",
      "Rank 1 : 17142 ~ 18570 polling Timeout... try again\n",
      "Rank 1 Polling:   0%|          | 0/1429 [00:03<?, ?msg/s]\n",
      "Rank 0 : 17142 ~ 18570 polling Timeout... try again\n",
      "Rank 0 Polling:   0%|          | 0/1429 [00:03<?, ?msg/s]\n",
      "Rank 2 : 17142 ~ 18570 polling Timeout... try again\n",
      "Rank 2 Polling:   0%|          | 0/1429 [00:03<?, ?msg/s]\n",
      "Rank 1 Polling:   0%|          | 0/1429 [00:00<?, ?msg/s]Rank 1 : Î©îÏÑ∏ÏßÄ Polling Start 18571 ~ 19999\n",
      "Rank 0 Polling:   0%|          | 0/1429 [00:00<?, ?msg/s]Rank 0 : Î©îÏÑ∏ÏßÄ Polling Start 18571 ~ 19999\n",
      "Rank 2 Polling:   0%|          | 0/1429 [00:00<?, ?msg/s]Rank 2 : Î©îÏÑ∏ÏßÄ Polling Start 18571 ~ 19999\n",
      "Rank 1 : 18571 ~ 19999 polling Timeout... try again\n",
      "Rank 1 Polling:   0%|          | 0/1429 [00:03<?, ?msg/s]\n",
      "[rank1]: Traceback (most recent call last):\n",
      "[rank1]:   File \"/tmp/tmpb8eaf_eo/train.py\", line 8, in <module>\n",
      "[rank1]:     output = train_fn(*args, **kwargs)\n",
      "[rank1]:   File \"/usr/local/lib/python3.9/dist-packages/ddp_kbit/experiments/runner.py\", line 292, in exp_fn\n",
      "[rank1]:     splited_datasets = DistributedDataFetcher(current_data_loader_config, device=init_config[\"device\"]) \\\n",
      "[rank1]:   File \"/usr/local/lib/python3.9/dist-packages/ddp_kbit/experiments/runner.py\", line 78, in fetch_n_pull_splited_datasets\n",
      "[rank1]:     datasets = self._create_datasets(offset_ranges, send_topic)\n",
      "[rank1]:   File \"/usr/local/lib/python3.9/dist-packages/ddp_kbit/experiments/runner.py\", line 103, in _create_datasets\n",
      "[rank1]:     dataset = DistributedDataset(\n",
      "[rank1]:   File \"/usr/local/lib/python3.9/dist-packages/ddp_kbit/data/datasets.py\", line 80, in __init__\n",
      "[rank1]:     self.data = self._load_data()\n",
      "[rank1]:   File \"/usr/local/lib/python3.9/dist-packages/ddp_kbit/data/datasets.py\", line 98, in _load_data\n",
      "[rank1]:     data.extend(random.choices(data, k=max_offset_diff + 1 - len(data)))\n",
      "[rank1]:   File \"/usr/lib/python3.9/random.py\", line 487, in choices\n",
      "[rank1]:     return [population[floor(random() * n)] for i in _repeat(None, k)]\n",
      "[rank1]:   File \"/usr/lib/python3.9/random.py\", line 487, in <listcomp>\n",
      "[rank1]:     return [population[floor(random() * n)] for i in _repeat(None, k)]\n",
      "[rank1]: IndexError: list index out of range\n",
      "Rank 0 : 18571 ~ 19999 polling Timeout... try again\n",
      "Rank 0 Polling:   0%|          | 0/1429 [00:03<?, ?msg/s]\n",
      "[rank0]: Traceback (most recent call last):\n",
      "[rank0]:   File \"/tmp/tmpr00o0834/train.py\", line 8, in <module>\n",
      "[rank0]:     output = train_fn(*args, **kwargs)\n",
      "[rank0]:   File \"/usr/local/lib/python3.9/dist-packages/ddp_kbit/experiments/runner.py\", line 292, in exp_fn\n",
      "[rank0]:     splited_datasets = DistributedDataFetcher(current_data_loader_config, device=init_config[\"device\"]) \\\n",
      "[rank0]:   File \"/usr/local/lib/python3.9/dist-packages/ddp_kbit/experiments/runner.py\", line 78, in fetch_n_pull_splited_datasets\n",
      "[rank0]:     datasets = self._create_datasets(offset_ranges, send_topic)\n",
      "[rank0]:   File \"/usr/local/lib/python3.9/dist-packages/ddp_kbit/experiments/runner.py\", line 103, in _create_datasets\n",
      "[rank0]:     dataset = DistributedDataset(\n",
      "[rank0]:   File \"/usr/local/lib/python3.9/dist-packages/ddp_kbit/data/datasets.py\", line 80, in __init__\n",
      "[rank0]:     self.data = self._load_data()\n",
      "[rank0]:   File \"/usr/local/lib/python3.9/dist-packages/ddp_kbit/data/datasets.py\", line 98, in _load_data\n",
      "[rank0]:     data.extend(random.choices(data, k=max_offset_diff + 1 - len(data)))\n",
      "[rank0]:   File \"/usr/lib/python3.9/random.py\", line 487, in choices\n",
      "[rank0]:     return [population[floor(random() * n)] for i in _repeat(None, k)]\n",
      "[rank0]:   File \"/usr/lib/python3.9/random.py\", line 487, in <listcomp>\n",
      "[rank0]:     return [population[floor(random() * n)] for i in _repeat(None, k)]\n",
      "[rank0]: IndexError: list index out of range\n",
      "Rank 2 : 18571 ~ 19999 polling Timeout... try again\n",
      "Rank 2 Polling:   0%|          | 0/1429 [00:03<?, ?msg/s]\n",
      "[rank2]: Traceback (most recent call last):\n",
      "[rank2]:   File \"/tmp/tmprj89so_g/train.py\", line 8, in <module>\n",
      "[rank2]:     output = train_fn(*args, **kwargs)\n",
      "[rank2]:   File \"/usr/local/lib/python3.9/dist-packages/ddp_kbit/experiments/runner.py\", line 292, in exp_fn\n",
      "[rank2]:     splited_datasets = DistributedDataFetcher(current_data_loader_config, device=init_config[\"device\"]) \\\n",
      "[rank2]:   File \"/usr/local/lib/python3.9/dist-packages/ddp_kbit/experiments/runner.py\", line 78, in fetch_n_pull_splited_datasets\n",
      "[rank2]:     datasets = self._create_datasets(offset_ranges, send_topic)\n",
      "[rank2]:   File \"/usr/local/lib/python3.9/dist-packages/ddp_kbit/experiments/runner.py\", line 103, in _create_datasets\n",
      "[rank2]:     dataset = DistributedDataset(\n",
      "[rank2]:   File \"/usr/local/lib/python3.9/dist-packages/ddp_kbit/data/datasets.py\", line 80, in __init__\n",
      "[rank2]:     self.data = self._load_data()\n",
      "[rank2]:   File \"/usr/local/lib/python3.9/dist-packages/ddp_kbit/data/datasets.py\", line 98, in _load_data\n",
      "[rank2]:     data.extend(random.choices(data, k=max_offset_diff + 1 - len(data)))\n",
      "[rank2]:   File \"/usr/lib/python3.9/random.py\", line 487, in choices\n",
      "[rank2]:     return [population[floor(random() * n)] for i in _repeat(None, k)]\n",
      "[rank2]:   File \"/usr/lib/python3.9/random.py\", line 487, in <listcomp>\n",
      "[rank2]:     return [population[floor(random() * n)] for i in _repeat(None, k)]\n",
      "[rank2]: IndexError: list index out of range\n",
      "[rank0]:[W820 14:00:42.937084629 ProcessGroupNCCL.cpp:1168] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())\n",
      "[rank2]:[W820 14:00:42.881107768 ProcessGroupNCCL.cpp:1168] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())\n",
      "[rank1]:[W820 14:00:42.308484907 ProcessGroupNCCL.cpp:1168] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())\n",
      "E0820 14:00:43.164515 140653709047616 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 0 (pid: 8729) of binary: /usr/bin/python3\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/run.py\", line 905, in <module>\n",
      "    main()\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 348, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/run.py\", line 901, in main\n",
      "    run(args)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/run.py\", line 892, in run\n",
      "    elastic_launch(\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/launcher/api.py\", line 133, in __call__\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/launcher/api.py\", line 264, in launch_agent\n",
      "    raise ChildFailedError(\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError:\n",
      "============================================================\n",
      "/tmp/tmpr00o0834/train.py FAILED\n",
      "------------------------------------------------------------\n",
      "Failures:\n",
      "  <NO_OTHER_FAILURES>\n",
      "------------------------------------------------------------\n",
      "Root Cause (first observed failure):\n",
      "[0]:\n",
      "  time      : 2025-08-20_14:00:43\n",
      "  host      : spark-worker-6455768c55-kxnb6\n",
      "  rank      : 0 (local_rank: 0)\n",
      "  exitcode  : 1 (pid: 8729)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "============================================================\n",
      "E0820 14:00:43.251464 140051709937472 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 0 (pid: 9189) of binary: /usr/bin/python3\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/run.py\", line 905, in <module>\n",
      "    main()\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 348, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/run.py\", line 901, in main\n",
      "    run(args)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/run.py\", line 892, in run\n",
      "    elastic_launch(\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/launcher/api.py\", line 133, in __call__\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/launcher/api.py\", line 264, in launch_agent\n",
      "    raise ChildFailedError(\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError:\n",
      "============================================================\n",
      "/tmp/tmprj89so_g/train.py FAILED\n",
      "------------------------------------------------------------\n",
      "Failures:\n",
      "  <NO_OTHER_FAILURES>\n",
      "------------------------------------------------------------\n",
      "Root Cause (first observed failure):\n",
      "[0]:\n",
      "  time      : 2025-08-20_14:00:43\n",
      "  host      : spark-worker-6455768c55-h44ld\n",
      "  rank      : 2 (local_rank: 0)\n",
      "  exitcode  : 1 (pid: 9189)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "============================================================\n",
      "E0820 14:00:43.280600 140112790341440 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 0 (pid: 8917) of binary: /usr/bin/python3\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/run.py\", line 905, in <module>\n",
      "    main()\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 348, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/run.py\", line 901, in main\n",
      "    run(args)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/run.py\", line 892, in run\n",
      "    elastic_launch(\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/launcher/api.py\", line 133, in __call__\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/launcher/api.py\", line 264, in launch_agent\n",
      "    raise ChildFailedError(\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError:\n",
      "============================================================\n",
      "/tmp/tmpb8eaf_eo/train.py FAILED\n",
      "------------------------------------------------------------\n",
      "Failures:\n",
      "  <NO_OTHER_FAILURES>\n",
      "------------------------------------------------------------\n",
      "Root Cause (first observed failure):\n",
      "[0]:\n",
      "  time      : 2025-08-20_14:00:43\n",
      "  host      : spark-worker-6455768c55-xzg5w\n",
      "  rank      : 1 (local_rank: 0)\n",
      "  exitcode  : 1 (pid: 8917)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "============================================================\n",
      "2025-08-20 14:00:43 - root - ERROR - Experiments failed: An error occurred while calling o262.collectToPython.\n",
      ": org.apache.spark.SparkException: Job aborted due to stage failure: Could not recover from a failed barrier ResultStage. Most recent failure reason: Stage failed because barrier task ResultTask(0, 0) finished unsuccessfully.\n",
      "org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/pyspark/ml/torch/distributor.py\", line 732, in wrapped_train_fn\n",
      "  File \"/opt/spark/python/lib/pyspark.zip/pyspark/ml/torch/distributor.py\", line 566, in _get_output_from_framework_wrapper\n",
      "    return framework_wrapper(\n",
      "  File \"/opt/spark/python/lib/pyspark.zip/pyspark/ml/torch/distributor.py\", line 914, in _run_training_on_pytorch_function\n",
      "    raise RuntimeError(\n",
      "RuntimeError: TorchDistributor failed during training.View stdout logs for detailed error message.\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n",
      "\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:118)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:2228)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3054)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2463)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1049)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:410)\n",
      "\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1048)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:448)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$collectToPython$1(Dataset.scala:4148)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4322)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4320)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:4320)\n",
      "\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:4145)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Single experiment failed: An error occurred while calling o262.collectToPython.\n",
      ": org.apache.spark.SparkException: Job aborted due to stage failure: Could not recover from a failed barrier ResultStage. Most recent failure reason: Stage failed because barrier task ResultTask(0, 0) finished unsuccessfully.\n",
      "org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/pyspark/ml/torch/distributor.py\", line 732, in wrapped_train_fn\n",
      "  File \"/opt/spark/python/lib/pyspark.zip/pyspark/ml/torch/distributor.py\", line 566, in _get_output_from_framework_wrapper\n",
      "    return framework_wrapper(\n",
      "  File \"/opt/spark/python/lib/pyspark.zip/pyspark/ml/torch/distributor.py\", line 914, in _run_training_on_pytorch_function\n",
      "    raise RuntimeError(\n",
      "RuntimeError: TorchDistributor failed during training.View stdout logs for detailed error message.\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n",
      "\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:118)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:2228)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3054)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2463)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1049)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:410)\n",
      "\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1048)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:448)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$collectToPython$1(Dataset.scala:4148)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4322)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4320)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:4320)\n",
      "\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:4145)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Single experiment\n",
    "print(\"üß™ Running single experiment...\")\n",
    "args.experiment_type = \"single\"\n",
    "\n",
    "try:\n",
    "    run_experiment_mode(args)\n",
    "    print(\"‚úÖ Single experiment completed successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Single experiment failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-20 14:00:44 - root - INFO - Starting experiment mode: multiple\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Running multiple experiments...\n",
      "FILES IN THIS DIRECTORY\n",
      "['DDP_KBIT', 'jars', 'config.json', 'mnist_pb2.py', 'spark_DL_checkpoints', 'sample_config.json']\n",
      "Current Spark configuration:\n",
      "spark.app.id = app-20250820140044-0059\n",
      "spark.app.initial.file.urls = spark://192.168.141.56:39337/files/mnist_pb2.py\n",
      "spark.app.initial.jar.urls = spark://192.168.141.56:39337/jars/jsr305-3.0.0.jar,spark://192.168.141.56:39337/jars/spark-sql-kafka-0-10_2.12-3.5.1.jar,spark://192.168.141.56:39337/jars/commons-pool2-2.11.1.jar,spark://192.168.141.56:39337/jars/rapids-4-spark_2.12-24.06.1.jar,spark://192.168.141.56:39337/jars/commons-logging-1.1.3.jar,spark://192.168.141.56:39337/jars/spark-token-provider-kafka-0-10_2.12-3.5.1.jar,spark://192.168.141.56:39337/jars/hadoop-client-runtime-3.3.4.jar,spark://192.168.141.56:39337/jars/lz4-java-1.8.0.jar,spark://192.168.141.56:39337/jars/kafka-clients-3.4.1.jar,spark://192.168.141.56:39337/jars/spark-streaming-kafka-0-10_2.12-3.5.1.jar,spark://192.168.141.56:39337/jars/slf4j-api-2.0.7.jar,spark://192.168.141.56:39337/jars/snappy-java-1.1.10.3.jar,spark://192.168.141.56:39337/jars/hadoop-client-api-3.3.4.jar\n",
      "spark.app.name = DDP_KBIT_Experiments\n",
      "spark.app.startTime = 1755698444211\n",
      "spark.app.submitTime = 1755698368149\n",
      "spark.defaul.parallelism = 30\n",
      "spark.default.parallelism = 64\n",
      "spark.driver.extraJavaOptions = -Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false\n",
      "spark.driver.host = 192.168.141.56\n",
      "spark.driver.port = 39337\n",
      "spark.executor.cores = 5\n",
      "spark.executor.extraJavaOptions = -Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false\n",
      "spark.executor.id = driver\n",
      "spark.executor.instances = 3\n",
      "spark.executor.memory = 24g\n",
      "spark.executor.resource.gpu.amount = 1\n",
      "spark.executor.resource.gpu.discoveryScript = /opt/spark/conf/getGpusResources.sh\n",
      "spark.files = file:///mnt/data/mnist_pb2.py\n",
      "spark.jars = jars/commons-logging-1.1.3.jar,jars/commons-pool2-2.11.1.jar,jars/hadoop-client-api-3.3.4.jar,jars/hadoop-client-runtime-3.3.4.jar,jars/jsr305-3.0.0.jar,jars/kafka-clients-3.4.1.jar,jars/lz4-java-1.8.0.jar,jars/slf4j-api-2.0.7.jar,jars/snappy-java-1.1.10.3.jar,jars/spark-sql-kafka-0-10_2.12-3.5.1.jar,jars/spark-streaming-kafka-0-10_2.12-3.5.1.jar,jars/spark-token-provider-kafka-0-10_2.12-3.5.1.jar,jars/rapids-4-spark_2.12-24.06.1.jar\n",
      "spark.master = spark://spark-master-service:7077\n",
      "spark.plugins = com.nvidia.spark.SQLPlugin\n",
      "spark.plugins.internal.conf.com.nvidia.spark.SQLPlugin.spark.rapids.driver.user.timezone = Z\n",
      "spark.plugins.internal.conf.com.nvidia.spark.SQLPlugin.spark.rapids.memory.gpu.minAllocFraction = 0.1\n",
      "spark.plugins.internal.conf.com.nvidia.spark.SQLPlugin.spark.rapids.memory.pinnedPool.size = 2g\n",
      "spark.plugins.internal.conf.com.nvidia.spark.SQLPlugin.spark.rapids.sql.concurrentGpuTasks = 1\n",
      "spark.plugins.internal.conf.com.nvidia.spark.SQLPlugin.spark.rapids.sql.multiThreadedRead.numThreads = 20\n",
      "spark.rapids.driver.user.timezone = Z\n",
      "spark.rapids.memory.gpu.minAllocFraction = 0.1\n",
      "spark.rapids.memory.pinnedPool.size = 2g\n",
      "spark.rapids.sql.concurrentGpuTasks = 1\n",
      "spark.rapids.sql.multiThreadedRead.numThreads = 20\n",
      "spark.rdd.compress = True\n",
      "spark.repl.local.jars = file:///mnt/data/jars/commons-logging-1.1.3.jar,file:///mnt/data/jars/commons-pool2-2.11.1.jar,file:///mnt/data/jars/hadoop-client-api-3.3.4.jar,file:///mnt/data/jars/hadoop-client-runtime-3.3.4.jar,file:///mnt/data/jars/jsr305-3.0.0.jar,file:///mnt/data/jars/kafka-clients-3.4.1.jar,file:///mnt/data/jars/lz4-java-1.8.0.jar,file:///mnt/data/jars/slf4j-api-2.0.7.jar,file:///mnt/data/jars/snappy-java-1.1.10.3.jar,file:///mnt/data/jars/spark-sql-kafka-0-10_2.12-3.5.1.jar,file:///mnt/data/jars/spark-streaming-kafka-0-10_2.12-3.5.1.jar,file:///mnt/data/jars/spark-token-provider-kafka-0-10_2.12-3.5.1.jar,file:///mnt/data/jars/rapids-4-spark_2.12-24.06.1.jar\n",
      "spark.serializer.objectStreamReset = 100\n",
      "spark.sql.extensions = com.nvidia.spark.rapids.SQLExecPlugin,com.nvidia.spark.udf.Plugin,com.nvidia.spark.rapids.optimizer.SQLOptimizerPlugin\n",
      "spark.sql.shuffle.partitions = 30\n",
      "spark.submit.deployMode = client\n",
      "spark.submit.pyFiles = mnist_pb2.py\n",
      "spark.task.resource.gpu.amount = 1\n",
      "spark.ui.showConsoleProgress = true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-20 14:00:45 - TorchDistributor - INFO - Started distributed training with 3 executor processes\n",
      "/usr/local/lib/python3.9/dist-packages/ignite/handlers/checkpoint.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
      "Warning: config.json not found. Using default values.\n",
      "/usr/local/lib/python3.9/dist-packages/ignite/handlers/checkpoint.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
      "Warning: config.json not found. Using default values.\n",
      "/usr/local/lib/python3.9/dist-packages/ignite/handlers/checkpoint.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
      "/usr/local/lib/python3.9/dist-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "Warning: config.json not found. Using default values.\n",
      "/usr/local/lib/python3.9/dist-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "Spark Command: /usr/local/openjdk-11/bin/java -cp $SPARK_HOME/jars/*.jar:/opt/spark/conf/:/opt/spark/jars/* -Xmx1g -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false org.apache.spark.deploy.SparkSubmit pyspark-shell\n",
      "========================================\n",
      "/usr/local/lib/python3.9/dist-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "Spark Command: /usr/local/openjdk-11/bin/java -cp $SPARK_HOME/jars/*.jar:/opt/spark/conf/:/opt/spark/jars/* -Xmx1g -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false org.apache.spark.deploy.SparkSubmit pyspark-shell\n",
      "========================================\n",
      "Spark Command: /usr/local/openjdk-11/bin/java -cp $SPARK_HOME/jars/*.jar:/opt/spark/conf/:/opt/spark/jars/* -Xmx1g -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false org.apache.spark.deploy.SparkSubmit pyspark-shell\n",
      "========================================\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/08/20 14:01:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/08/20 14:01:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "Starting 5 iterations of experiments...\n",
      "\n",
      "==================================================\n",
      "Ïã§Ìóò Î∞òÎ≥µ 1/5\n",
      "==================================================\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/tmpckkxt9n6/train.py\", line 8, in <module>\n",
      "    output = train_fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/ddp_kbit/experiments/runner.py\", line 403, in run_multiple_experiments\n",
      "    num_processes=int(sc.getConf().get(\"spark.executor.instances\")),\n",
      "TypeError: int() argument must be a string, a bytes-like object or a number, not 'NoneType'\n",
      "25/08/20 14:01:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Starting 5 iterations of experiments...\n",
      "\n",
      "==================================================\n",
      "Ïã§Ìóò Î∞òÎ≥µ 1/5\n",
      "==================================================\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/tmp8udt4axm/train.py\", line 8, in <module>\n",
      "    output = train_fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/ddp_kbit/experiments/runner.py\", line 403, in run_multiple_experiments\n",
      "    num_processes=int(sc.getConf().get(\"spark.executor.instances\")),\n",
      "TypeError: int() argument must be a string, a bytes-like object or a number, not 'NoneType'\n",
      "E0820 14:01:15.252070 140304258221888 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 0 (pid: 8869) of binary: /usr/bin/python3\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/run.py\", line 905, in <module>\n",
      "    main()\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 348, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/run.py\", line 901, in main\n",
      "    run(args)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/run.py\", line 892, in run\n",
      "    elastic_launch(\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/launcher/api.py\", line 133, in __call__\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/launcher/api.py\", line 264, in launch_agent\n",
      "    raise ChildFailedError(\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError:\n",
      "============================================================\n",
      "/tmp/tmpckkxt9n6/train.py FAILED\n",
      "------------------------------------------------------------\n",
      "Failures:\n",
      "  <NO_OTHER_FAILURES>\n",
      "------------------------------------------------------------\n",
      "Root Cause (first observed failure):\n",
      "[0]:\n",
      "  time      : 2025-08-20_14:01:15\n",
      "  host      : spark-worker-6455768c55-kxnb6\n",
      "  rank      : 0 (local_rank: 0)\n",
      "  exitcode  : 1 (pid: 8869)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "============================================================\n",
      "Starting 5 iterations of experiments...\n",
      "\n",
      "==================================================\n",
      "Ïã§Ìóò Î∞òÎ≥µ 1/5\n",
      "==================================================\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/tmpg_vjy3u6/train.py\", line 8, in <module>\n",
      "    output = train_fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/ddp_kbit/experiments/runner.py\", line 403, in run_multiple_experiments\n",
      "    num_processes=int(sc.getConf().get(\"spark.executor.instances\")),\n",
      "TypeError: int() argument must be a string, a bytes-like object or a number, not 'NoneType'\n",
      "E0820 14:01:15.564164 139744742664000 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 0 (pid: 9316) of binary: /usr/bin/python3\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/run.py\", line 905, in <module>\n",
      "    main()\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 348, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/run.py\", line 901, in main\n",
      "    run(args)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/run.py\", line 892, in run\n",
      "    elastic_launch(\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/launcher/api.py\", line 133, in __call__\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/launcher/api.py\", line 264, in launch_agent\n",
      "    raise ChildFailedError(\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError:\n",
      "============================================================\n",
      "/tmp/tmp8udt4axm/train.py FAILED\n",
      "------------------------------------------------------------\n",
      "Failures:\n",
      "  <NO_OTHER_FAILURES>\n",
      "------------------------------------------------------------\n",
      "Root Cause (first observed failure):\n",
      "[0]:\n",
      "  time      : 2025-08-20_14:01:15\n",
      "  host      : spark-worker-6455768c55-h44ld\n",
      "  rank      : 1 (local_rank: 0)\n",
      "  exitcode  : 1 (pid: 9316)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "============================================================\n",
      "2025-08-20 14:01:15 - root - ERROR - Experiments failed: An error occurred while calling o394.collectToPython.\n",
      ": org.apache.spark.SparkException: Job aborted due to stage failure: Could not recover from a failed barrier ResultStage. Most recent failure reason: Stage failed because barrier task ResultTask(0, 0) finished unsuccessfully.\n",
      "org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/pyspark/ml/torch/distributor.py\", line 732, in wrapped_train_fn\n",
      "  File \"/opt/spark/python/lib/pyspark.zip/pyspark/ml/torch/distributor.py\", line 566, in _get_output_from_framework_wrapper\n",
      "    return framework_wrapper(\n",
      "  File \"/opt/spark/python/lib/pyspark.zip/pyspark/ml/torch/distributor.py\", line 914, in _run_training_on_pytorch_function\n",
      "    raise RuntimeError(\n",
      "RuntimeError: TorchDistributor failed during training.View stdout logs for detailed error message.\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n",
      "\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:118)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:2228)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3054)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2463)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1049)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:410)\n",
      "\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1048)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:448)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$collectToPython$1(Dataset.scala:4148)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4322)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4320)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:4320)\n",
      "\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:4145)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Multiple experiments failed: An error occurred while calling o394.collectToPython.\n",
      ": org.apache.spark.SparkException: Job aborted due to stage failure: Could not recover from a failed barrier ResultStage. Most recent failure reason: Stage failed because barrier task ResultTask(0, 0) finished unsuccessfully.\n",
      "org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/pyspark/ml/torch/distributor.py\", line 732, in wrapped_train_fn\n",
      "  File \"/opt/spark/python/lib/pyspark.zip/pyspark/ml/torch/distributor.py\", line 566, in _get_output_from_framework_wrapper\n",
      "    return framework_wrapper(\n",
      "  File \"/opt/spark/python/lib/pyspark.zip/pyspark/ml/torch/distributor.py\", line 914, in _run_training_on_pytorch_function\n",
      "    raise RuntimeError(\n",
      "RuntimeError: TorchDistributor failed during training.View stdout logs for detailed error message.\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n",
      "\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:118)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:893)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:893)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:2228)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3054)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2463)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1049)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:410)\n",
      "\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1048)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:448)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$collectToPython$1(Dataset.scala:4148)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4322)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4320)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:4320)\n",
      "\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:4145)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Multiple experiments with statistical analysis\n",
    "print(\"üß™ Running multiple experiments...\")\n",
    "args.experiment_type = \"multiple\"\n",
    "args.iterations = 5  # You can change this number\n",
    "\n",
    "try:\n",
    "    run_experiment_mode(args)\n",
    "    print(f\"‚úÖ {args.iterations} experiments completed successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Multiple experiments failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions\n",
    "\n",
    "Helper functions for notebook usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Utility functions loaded!\n",
      "\n",
      "Use these functions for quick execution:\n",
      "- quick_train(distributed=False)\n",
      "- quick_experiment(experiment_type='multiple', iterations=5)\n"
     ]
    }
   ],
   "source": [
    "def quick_train(distributed=False, config_path=\"sample_config.json\"):\n",
    "    \"\"\"Quick training function for easy execution.\"\"\"\n",
    "    args.distributed = distributed\n",
    "    args.config_path = config_path\n",
    "    \n",
    "    print(f\"üöÄ Quick training - Distributed: {distributed}\")\n",
    "    try:\n",
    "        run_training_mode(args)\n",
    "        print(\"‚úÖ Training completed!\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Training failed: {e}\")\n",
    "\n",
    "def quick_experiment(experiment_type=\"single\", iterations=3):\n",
    "    \"\"\"Quick experiment function for easy execution.\"\"\"\n",
    "    args.experiment_type = experiment_type\n",
    "    args.iterations = iterations\n",
    "    \n",
    "    print(f\"üß™ Quick experiment - Type: {experiment_type}, Iterations: {iterations}\")\n",
    "    try:\n",
    "        run_experiment_mode(args)\n",
    "        print(\"‚úÖ Experiment completed!\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Experiment failed: {e}\")\n",
    "\n",
    "print(\"‚úì Utility functions loaded!\")\n",
    "print(\"\\nUse these functions for quick execution:\")\n",
    "print(\"- quick_train(distributed=False)\")\n",
    "print(\"- quick_experiment(experiment_type='multiple', iterations=5)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Execution Examples\n",
    "\n",
    "Use the utility functions for quick execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí° Uncomment the lines above to run quick examples!\n"
     ]
    }
   ],
   "source": [
    "# Example: Quick single training\n",
    "# quick_train()\n",
    "\n",
    "# Example: Quick multiple experiments\n",
    "# quick_experiment(experiment_type=\"multiple\", iterations=3)\n",
    "\n",
    "print(\"üí° Uncomment the lines above to run quick examples!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
